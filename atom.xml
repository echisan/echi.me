<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>EchisanBlog</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-01-27T14:55:21.377Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>k8s下的spirngboot跨域问题</title>
    <link href="http://example.com/2019/12/04/k8s-springboot-cors/"/>
    <id>http://example.com/2019/12/04/k8s-springboot-cors/</id>
    <published>2019-12-04T08:35:05.000Z</published>
    <updated>2021-01-27T14:55:21.377Z</updated>
    
    <content type="html"><![CDATA[<h2 id="很烦的跨域问题"><a href="#很烦的跨域问题" class="headerlink" title="很烦的跨域问题"></a>很烦的跨域问题</h2><p>在前后端分离的情况下，假如在springboot没配置cors的情况下，就会出现这样的问题。</p><pre class="line-numbers language-none"><code class="language-none">Access to XMLHttpRequest at &#39;http:&#x2F;&#x2F;localhost:8080&#x2F;api&#39; from origin &#39;http:&#x2F;&#x2F;localhost:63342&#39; has been blocked by CORS policy: Response to preflight request doesn&#39;t pass access control check: No &#39;Access-Control-Allow-Origin&#39; header is present on the requested resource.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>那很简单，只要重写一下<code>WebMvcConfigurer</code>下的<code>addCorsMappings</code>方法就可以了，<em>真就这么容易就好了，草</em></p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Overridepublic void addCorsMappings(CorsRegistry registry) &#123;    registry.addMapping(&quot;&#x2F;**&quot;)            .allowedOrigins(&quot;*&quot;)            .allowedMethods(&quot;POST&quot;, &quot;GET&quot;, &quot;PUT&quot;, &quot;OPTIONS&quot;, &quot;DELETE&quot;)            .allowCredentials(true);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>根据以往的经验，一般请求链如下，通过浏览器然后通过nginx反向代理到springboot应用，按照从前来一直都没问题</p><pre class="line-numbers language-none"><code class="language-none">web browser --&gt; nginx --&gt; springboot<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>但是我自己写了一个ajax在本地测试，发现是没有问题的，但是推送到测试服务器供前端测试的时候却不行</p><pre class="line-numbers language-javascript" data-language="javascript"><code class="language-javascript">$<span class="token punctuation">.</span><span class="token function">ajax</span><span class="token punctuation">(</span><span class="token punctuation">&#123;</span>            method<span class="token operator">:</span> <span class="token string">"POST"</span><span class="token punctuation">,</span>            url<span class="token operator">:</span> <span class="token string">"http://localhost:8080/api"</span><span class="token punctuation">,</span>        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">then</span><span class="token punctuation">(</span><span class="token keyword">function</span> <span class="token punctuation">(</span><span class="token parameter">value</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>            console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="allowedHeader配置"><a href="#allowedHeader配置" class="headerlink" title="allowedHeader配置"></a>allowedHeader配置</h2><p>然后前端那边提醒说到有自定义的请求头，然后我再测试，发现我本地也不行了</p><pre class="line-numbers language-javascript" data-language="javascript"><code class="language-javascript">$<span class="token punctuation">.</span><span class="token function">ajax</span><span class="token punctuation">(</span><span class="token punctuation">&#123;</span>            method<span class="token operator">:</span> <span class="token string">"POST"</span><span class="token punctuation">,</span>            url<span class="token operator">:</span> <span class="token string">"http://localhost:8080/api"</span><span class="token punctuation">,</span>            headers<span class="token operator">:</span><span class="token punctuation">&#123;</span>                <span class="token string">"token"</span><span class="token operator">:</span><span class="token string">"abc"</span>            <span class="token punctuation">&#125;</span>        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">then</span><span class="token punctuation">(</span><span class="token keyword">function</span> <span class="token punctuation">(</span><span class="token parameter">value</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>            console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后再修改springboot里的配置，在通过上面的ajax测试，发现成了，然后高兴推送到测试服务器，结果我再测试发现依然不行</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Overridepublic void addCorsMappings(CorsRegistry registry) &#123;    registry.addMapping(&quot;&#x2F;**&quot;)            .allowedOrigins(&quot;*&quot;)            .allowedMethods(&quot;POST&quot;, &quot;GET&quot;, &quot;PUT&quot;, &quot;OPTIONS&quot;, &quot;DELETE&quot;)            .allowedHeaders(&quot;token&quot;)            .allowCredentials(true);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h2><p>然后因为往常nginx也没有配置，发现也没有问题，然后这次居然不行，然后把目光投向k8s的<code>nginx-ingress</code></p><p>接着google了一番，发现<code>Ingress</code>需要配置几个<code>Annotation</code><br>最后  </p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">apiVersion: extensions&#x2F;v1beta1kind: Ingressmetadata:  name: demo  namespace: demo  annotations:    nginx.ingress.kubernetes.io&#x2F;enable-cors: &quot;true&quot;    nginx.ingress.kubernetes.io&#x2F;cors-allow-methods: &quot;PUT, GET, POST, OPTIONS&quot;    nginx.ingress.kubernetes.io&#x2F;cors-allow-origin: &quot;*&quot;    nginx.ingress.kubernetes.io&#x2F;cors-allow-headers: &quot;token&quot;    nginx.ingress.kubernetes.io&#x2F;cors-allow-credentials: &quot;true&quot;spec:  rules:  - host: api.demo.com    http:      paths:      - path: &#x2F;        backend:          serviceName: demo-service          servicePort: 80<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后通过上述操作，终于可以了</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;很烦的跨域问题&quot;&gt;&lt;a href=&quot;#很烦的跨域问题&quot; class=&quot;headerlink&quot; title=&quot;很烦的跨域问题&quot;&gt;&lt;/a&gt;很烦的跨域问题&lt;/h2&gt;&lt;p&gt;在前后端分离的情况下，假如在springboot没配置cors的情况下，就会出现这样的问题。&lt;/p&gt;</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
    <category term="springboot" scheme="http://example.com/tags/springboot/"/>
    
    <category term="cors" scheme="http://example.com/tags/cors/"/>
    
    <category term="ingress-nginx" scheme="http://example.com/tags/ingress-nginx/"/>
    
  </entry>
  
  <entry>
    <title>hotspot垃圾收集器</title>
    <link href="http://example.com/2019/11/29/hotspot-gc/"/>
    <id>http://example.com/2019/11/29/hotspot-gc/</id>
    <published>2019-11-29T10:08:15.000Z</published>
    <updated>2021-01-27T14:55:21.383Z</updated>
    
    <content type="html"><![CDATA[<h2 id="hotspot虚拟机垃圾收集器"><a href="#hotspot虚拟机垃圾收集器" class="headerlink" title="hotspot虚拟机垃圾收集器"></a>hotspot虚拟机垃圾收集器</h2><p>垃圾收集器目前来说有：</p><ul><li>Serial(串行)</li><li>parnew(Serial收集器的多线程版本)</li><li>parallel scavenge(并行清除)</li><li>serial old</li><li>parallel old</li><li>cms</li><li>g1</li></ul><p><strong>新生代收集器</strong></p><ul><li>Serial</li><li>ParNew</li><li>Parallel Scavenge</li><li>(G1)</li></ul><p><strong>老年代收集器</strong></p><ul><li>CMS</li><li>Serial Old(MSC)</li><li>Parallel Old</li><li>(G1)</li></ul><h2 id="复习下收集算法"><a href="#复习下收集算法" class="headerlink" title="复习下收集算法"></a>复习下收集算法</h2><h3 id="标记-清除算法"><a href="#标记-清除算法" class="headerlink" title="标记-清除算法"></a>标记-清除算法</h3><p>描述：如同名字一样，先标记后收集<br>缺点： 效率问题，标记、收集两个过程效率都不高。另一个是空间问题，标记清除后会产生大量不连续的内存碎片，导致以后程序需要分配较大对象时，无法找到足够内存而不得不触发另一次垃圾收集动作</p><p><img src="https://user-images.githubusercontent.com/38010908/69610588-0e8cb600-1067-11ea-9a76-95530c6c723d.png" alt="image"></p><h3 id="复制算法"><a href="#复制算法" class="headerlink" title="复制算法"></a>复制算法</h3><p>描述：将可用内存按照容量分为大小相等的两块，当这一块内存用完了，就将还存活的对象复制到另一块上，然后再把已使用过的内存空间一次清理掉。<br>优点：进行垃圾收集时，对整个半区进行内存回收，内存分配也不用考虑内存碎片等复杂情况<br>缺点：将内存缩小了为原来的一半，代价过大</p><p><img src="https://user-images.githubusercontent.com/38010908/69611524-e8681580-1068-11ea-8ac5-7130372ce75f.png" alt="image"></p><blockquote><p>现在的商业虚拟机都采用该收集算法来回收新生代，由于新生代中对象98%是“朝生夕死”的，所以不需要1:1比例划分内存空间，所以分为一块较大的Eden空间以及两块较小的Survivor空间，每次使用eden以及其中一块Survivor</p></blockquote><p>回收过程：<br>将Eden以及Survivor中还存活的对象一次性复制到另外一块Survivor空间中，最后清理掉刚才用过的Survivor空间</p><blockquote><p>我们没办法确保每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他内存(这里指老年代)进行分配担保。</p></blockquote><p>分配担保：</p><blockquote><p>在垃圾收集过程中，如果另外一块Survivor没有足够空间存放上一次新生代收集下来的对象，则通过分配担保机制进入老年代。</p></blockquote><p>担保机制：  </p><p>主要讲JDK1.6之后的。<br>如果老年代可用的连续内存大小大于新生代对象总大小或者对象历次晋升的平均大小(也就是每次经过MinorGC之后还存活的对象的平均大小)，那么就进行MinorGC，否则就进行Full GC。</p><p><img src="https://user-images.githubusercontent.com/38010908/69612170-244faa80-106a-11ea-98e9-3e16ae7f0e9d.png" alt="image"></p><h2 id="标记-整理算法"><a href="#标记-整理算法" class="headerlink" title="标记-整理算法"></a>标记-整理算法</h2><p>复制-收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中对象100%存活的极端情况，所以老年代一般不能直接选用这种算法。</p><p>根据老年代的特点，标记过程仍然与(标记-清除)一样，但是清除步骤换成整理，让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存</p><p><img src="https://user-images.githubusercontent.com/38010908/69615011-210aed80-106f-11ea-984d-dce14368fa19.png" alt="image"></p><h2 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h2><p>当代商业虚拟机的垃圾收集都采用“分代收集”(Generational Collection)算法，这种算法并没有什么新的思想，只是根据对象存活周期的不同将内存划分为几块。<br>一般是把java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。</p><hr><h2 id="Parallel-Scavenge"><a href="#Parallel-Scavenge" class="headerlink" title="Parallel Scavenge"></a>Parallel Scavenge</h2><p>并行的多线程的收集器，看似跟ParNew是一样的，但是是有区别的。</p><blockquote><p>Parallel Scavenge收集器架构中本身有PS MarkSweep收集器进行老年代收集，并非直接使用Serial Old收集器，但是这个PS MarkSweep收集器与Serial Old的实现非常接近</p></blockquote><p>Parallel Scavenge收集器的目标是达到一个可控制的吞吐量。<br>所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即</p><p><code>吞吐量 = 运行用户代码时间 / (运行用户代码时间+垃圾收集时间)</code></p><p>Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量</p><ul><li>控制最大垃圾收集器停顿时间(-XX:MaxGCPauseMills)<blockquote><p>允许值是一个大于0的毫秒数</p></blockquote></li><li>设置吞吐量大小(-XX:GCTimeRatio)<blockquote><p>参数是一个大于0且小于100的整数，也就是垃圾收集时间占总时间比率，相当于是吞吐量的倒数</p></blockquote></li><li>自适应调节策略(-XX:+UseAdaptiveSizePolicy)<blockquote><p>打开这个参数后不需要手动指定新生代的大小(-Xmn)、Eden与Survivor区的比例(-XX:SurvivorRatio)、晋升老年代对象年龄(-XX:PretenureSizeThreshold)等参数，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适停顿时间或最大的吞吐量</p></blockquote></li></ul><h2 id="Parallel-Old"><a href="#Parallel-Old" class="headerlink" title="Parallel Old"></a>Parallel Old</h2><p>Parallel Old 是Parallel Scavenge Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法</p><blockquote><p>在没有Parallel Old收集器的时候，如果选择了Parallel Scavenge作为新生代收集器，那么老年代出了Serial Old收集器之外别无选择</p></blockquote><p>直到Parallel Old收集器出现后，“吞吐量优先”的收集器才有了比较名副其实的应用组合，在注重吞吐量以及CPU资源敏感的场合，可以优先考虑Parallel Scavenge加Parallel Old收集器</p><p><img src="https://user-images.githubusercontent.com/38010908/69698111-62f36c80-111f-11ea-92b1-a53870f69d4c.png" alt="image"></p><h2 id="Serial-amp-amp-Serial-Old"><a href="#Serial-amp-amp-Serial-Old" class="headerlink" title="Serial &amp;&amp; Serial Old"></a>Serial &amp;&amp; Serial Old</h2><p>单线程<br>Serial新生代使用复制算法<br>Serial old老年代使用标记整理算法</p><blockquote><p>Serial Old收集器意义在于给client模式下的虚拟机使用。<br>在Server模式下，有两大用途：1、在JDK1.5以及之前版本与Parallel Scavenge收集器配合使用，另一种就是作为CMS收集器后备预案，在并发收集发生Concurrent Mode Failure时使用 </p></blockquote><p><img src="https://user-images.githubusercontent.com/38010908/69610367-a047f380-1066-11ea-8280-20eb52c5ccb6.png" alt="image"></p><h2 id="ParNew"><a href="#ParNew" class="headerlink" title="ParNew"></a>ParNew</h2><p>ParNew收集器其实就是Serial收集器的多线程版本，是Server模式下的首选新生代收集器(主要是因为只有ParNew收集器能与CMS老年代收集器配合工作)</p><blockquote><p>不幸的是，CMS无法与Parallel Scavenge新生代收集器配合使用。<br>所以如果选择CMS作为老年代收集器，新生代只能选择ParNew跟Serial收集器其中一个</p></blockquote><p>所以使用<code>-XX:+UseConcMarkSweepGc</code>的选项后ParNew也是默认的新生代收集器</p><blockquote><p>可以使用<code>-XX:ParallelGCThreads</code>参数限制垃圾收集的线程数</p></blockquote><p><img src="https://user-images.githubusercontent.com/38010908/69622727-7bf71180-107c-11ea-88a1-cb515a1af4fe.png" alt="image"></p><h2 id="CMS"><a href="#CMS" class="headerlink" title="CMS"></a>CMS</h2><p>CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的收集器。</p><p>从名字Mark Sweep可以看出来，CMS也是基于标记-清除算法实现的，但是比前面几种收集器来说更复杂一点。</p><ul><li>初始标记(CMS initial mark)<blockquote><p>初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快 </p></blockquote></li><li>并发标记(CMS concurrent mark)<blockquote><p> 并发标记阶段就是进行GC Roots Tracing的过程</p></blockquote></li><li>重新标记(CMS remark) <blockquote><p>重新标记是为了修正并发标记期间用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段停顿的时间一般比初始标记阶段稍长一些，但远比并发标记的时间短</p></blockquote></li><li>并发清除(CMS concurrent sweep)</li></ul><p>其中初始标记、重新标记仍然需要”Stop The World”。</p><blockquote><p>由于整个过程中耗时最长的并发标记和并发清除过程线程都可以与用户线程一起工作，所以，总体上说，CMS收集器的内存回收过程是与用户线程一起并发执行的</p></blockquote><p><img src="https://user-images.githubusercontent.com/38010908/69699982-4ad21c00-1124-11ea-9894-f96ab5e3b240.png" alt="image"></p><p>CMS的3个明显缺点。</p><ol><li>CMS收集器对CPU资源非常敏感</li></ol><p>在默认情况下，CMS默认启动的回收线程计算方式如下  </p><pre class="line-numbers language-none"><code class="language-none">启动的回收线程数 &#x3D; (CPU数量+3)&#x2F;4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>也就是在4核的情况下，会启动1条回收线程，在并发回收时回收线程会占用不少于25%的CPU资源，不过随着CPU的数量增加会下降。</p><p>但是，当CPU不足4个的时候，比如2个，那么则会占用不少于50%的运算能力去执行收集线程，这是无法忍受的。  </p><blockquote><p>因此虚拟机提供了一种称为“增量式并发收集器”(I ncremental Concurrent Mark  Sweep/i-CMS)的CMS收集器变种，原理就是在并发回收的时候，用户线程跟回收线程交替执行，虽然回收的时间更长，但是对用户程序影响变小的。**但是实践证明，该增量CMS收集器效果很一般，以被声明<code>deprecated</code>，不再提倡用户使用了</p></blockquote><ol start="2"><li>CMS收集器无法处理浮动垃圾(Floating Garbage)，可能出现”Concurrent Mode Failure”失败而导致另一次Full GC的产生</li></ol><p><strong>浮动垃圾</strong>：<br>由于CMS并发清理阶段用户线程还在运行着，伴随着程序运行自然还会有新的垃圾不断产生，这一部分垃圾在标记过程之后，CMS无法在当次收集中处理它们，只好留待下次GC时再清理掉。这部分垃圾就叫做浮动垃圾。</p><p>因为在垃圾收集阶段用户线程还需要运行，那也是需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间踢空并发收集时程序运行作使用。</p><p>这部分预留的空间可以通过<code>-XX:CMSInitiatingOccupancyFraction</code>的值进行修改。JDK1.6中，默认值为92%</p><p>当CMS运行期间预留的内存无法满足程序需要，就会出现一次”Concurrent Mode Failure”失败，这时虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集，不过这样等待的时间就长了。</p><ol start="3"><li>CMS是基于“标记-清除”算法实现的，意味着收集完之后，会有大量的空间碎片。</li></ol><p>当碎片过多时，会出现尽管老年代还有很大的空间剩余，却无法找到足够大的连续空间来分配当前对象，不得不提前出发一次full GC。</p><p>为此，CMS提供了一个参数 <code>-XX:+UseCMSCompactAtFullCollection</code>用于开启CMS对空间进行整理,用于在CMS在顶不住要进行Full GC时开启内存碎片的合并整理过程，不过，整理过程是无法并发的，空间碎片问题没有了，不过停顿时间不得不变长了。</p><p>但是，虚拟机设计者又提供了另外一个参数<code>-XX:CMSFullGCsBeforeCompaction</code>这个参数用于设置执行多少次不压缩的Full GC后，跟着来一次带压缩的(默认为0，表示每次进入Full GC时都进行碎片整理)</p><h2 id="G1"><a href="#G1" class="headerlink" title="G1"></a>G1</h2><p>G1是一款面向服务端应用的垃圾收集器，与其他GC收集器相比，G1具备如下特点：</p><ul><li>并行与并发<blockquote><p>G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短STW停顿的时间，部分其他收集器原本需要停顿java线程执行的GC动作，G1仍然可以通过并发的方式让java程序继续执行</p></blockquote></li><li>分代收集<blockquote><p>虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活一段时间、熬过多次GC的旧对象以获取更好的收集效果</p></blockquote></li><li>空间整合<blockquote><p>G1整体来看是基于“标记-整理”算法实现的收集器，从局部(两个Region之间)上来看是基于”复制”算法实现的。但不管怎么说，G1在运作期间不会产生内存碎片空间，收集后能提供规整的可用内存</p></blockquote></li><li>可预测的停顿<blockquote><p>G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集器上的时间不得超过N毫秒。</p></blockquote></li></ul><p>在G1之前的其他收集器的范围都是整个新生代或者老年代，而G1不再是这样。在使用G1收集器时，java堆的内存布局就与其他收集器有很大差别，它将java堆划分为多个大小相等的独立区域(Region)。虽然还有新生代老年代的概念，但是不再是物理隔离了，他们都是一部分Region的集合。</p><p>G1建立可预测停顿时间模型的原因：</p><p>因为G1可以有计划地避免在整个java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小(回收所获得的空间大小以及回收所需时间的经验值)，在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。这种使用Region划分内存空间以及优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。</p><blockquote><p>在G1中，Region之间的对象引用以及其他收集器中的新生代与老年代之前的对象引用，虚拟机都是使用Remembered Set来避免扫描全堆的。<br>G1中每个Region都有一个与之对应的Remembered Set，虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个Write Barrier暂时中断写操作，检查Reference引用的对象是否处于不同的Region之中(在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象)，如果是，便通过CardTable把相关引用信息记录到被引用对象所属的Region的Remembered Set中。当进行内存回收时，在GC根节点的枚举范围中加入Remembered Set即可保证不对全表扫描也不会有遗漏</p></blockquote><p><a href="https://juejin.im/post/5b8d2a5551882542ba1ddcf8">gc相关的、卡表说明</a></p><p>如果不计算维护Remembered Set的操作，G1收集器的运作大致可划分为一下几个步骤：</p><ul><li>初始标记(Initial Marking)</li><li>并发标记(Concurrent Marking)</li><li>最终标记(Final Marking)</li><li>筛选回收(Live Data Counting and Evacuation)</li></ul><p><img src="https://user-images.githubusercontent.com/38010908/69709345-2c761b80-1138-11ea-9c77-49e3005a9433.png" alt="image"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;hotspot虚拟机垃圾收集器&quot;&gt;&lt;a href=&quot;#hotspot虚拟机垃圾收集器&quot; class=&quot;headerlink&quot; title=&quot;hotspot虚拟机垃圾收集器&quot;&gt;&lt;/a&gt;hotspot虚拟机垃圾收集器&lt;/h2&gt;&lt;p&gt;垃圾收集器目前来说有：&lt;/p&gt;
&lt;u</summary>
      
    
    
    
    
    <category term="java" scheme="http://example.com/tags/java/"/>
    
    <category term="gc" scheme="http://example.com/tags/gc/"/>
    
    <category term="hotspot" scheme="http://example.com/tags/hotspot/"/>
    
    <category term="jvm" scheme="http://example.com/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>k8s或docker中运行arthas出现&quot;Unable to get pid of LinuxThreads manager thread&quot;的问题</title>
    <link href="http://example.com/2019/11/13/k8s-arthas-managerthread-problem/"/>
    <id>http://example.com/2019/11/13/k8s-arthas-managerthread-problem/</id>
    <published>2019-11-13T07:36:51.000Z</published>
    <updated>2021-01-27T14:55:21.366Z</updated>
    
    <content type="html"><![CDATA[<h2 id="情景模拟"><a href="#情景模拟" class="headerlink" title="情景模拟"></a>情景模拟</h2><p>现在有一个很简单的景象，把arthas复制进去，并且运行arthas-demo</p><pre class="line-numbers language-dockerfile" data-language="dockerfile"><code class="language-dockerfile">FROM openjdk:8-jdk-alpineCOPY --from&#x3D;hengyunabc&#x2F;arthas:latest &#x2F;opt&#x2F;arthas &#x2F;opt&#x2F;arthasCMD [&quot;java&quot;,&quot;-jar&quot;,&quot;&#x2F;opt&#x2F;arthas&#x2F;arthas-demo.jar&quot;]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>然后进入容器运行arthas，会提示<code>Unable to get pid of LinuxThreads manager thread</code>这个错误</p><pre class="line-numbers language-none"><code class="language-none">&#x2F;opt&#x2F;arthas # java -jar arthas-boot.jar [INFO] arthas-boot version: 3.1.3[INFO] Found existing java process, please choose one and hit RETURN.* [1]: 1 &#x2F;opt&#x2F;arthas&#x2F;arthas-demo.jar1[INFO] arthas home: &#x2F;opt&#x2F;arthas[INFO] Try to attach process 1[ERROR] Start arthas failed, exception stack trace: com.sun.tools.attach.AttachNotSupportedException: Unable to get pid of LinuxThreads manager threadat sun.tools.attach.LinuxVirtualMachine.&lt;init&gt;(LinuxVirtualMachine.java:86)at sun.tools.attach.LinuxAttachProvider.attachVirtualMachine(LinuxAttachProvider.java:78)at com.sun.tools.attach.VirtualMachine.attach(VirtualMachine.java:250)at com.taobao.arthas.core.Arthas.attachAgent(Arthas.java:82)at com.taobao.arthas.core.Arthas.&lt;init&gt;(Arthas.java:28)at com.taobao.arthas.core.Arthas.main(Arthas.java:120)[ERROR] attach fail, targetPid: 1&#x2F;opt&#x2F;arthas # <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>google了下，发现只有在arthas的github中的issue有讨论下，那里提到解决方案有两种</p><ol><li>第一种是如下<br><code>docker run --init my-app</code></li></ol><blockquote><p>但是由于我的docker镜像是跑在k8s上的，不由得我来run，所以放弃这种方案</p></blockquote><ol start="2"><li>第二种是在镜像中添加init功能<br>就是将<a href="https://github.com/krallin/tini">tini</a>添加到镜像中</li></ol><p>最简单的方案就是如下</p><pre class="line-numbers language-dockerfile" data-language="dockerfile"><code class="language-dockerfile">COPY --from&#x3D;hengyunabc&#x2F;arthas:latest &#x2F;opt&#x2F;arthas &#x2F;opt&#x2F;arthasRUN apk add --no-cache tiniENTRYPOINT [&quot;&#x2F;sbin&#x2F;tini&quot;, &quot;--&quot;]CMD [&quot;java&quot;,&quot;-jar&quot;,&quot;&#x2F;opt&#x2F;arthas&#x2F;arthas-demo.jar&quot;]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>现在查看进程会发现pid为1的进程已经变成tini了</p><pre class="line-numbers language-none"><code class="language-none">&#x2F;opt&#x2F;arthas # ps -efPID   USER     TIME  COMMAND    1 root      0:00 &#x2F;usr&#x2F;bin&#x2F;tini -- java -jar &#x2F;opt&#x2F;arthas&#x2F;arthas-demo.jar    7 root      0:00 java -jar &#x2F;opt&#x2F;arthas&#x2F;arthas-demo.jar   19 root      0:00 sh   55 root      0:00 ps -ef&#x2F;opt&#x2F;arthas # <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>再去运行arthas</p><pre class="line-numbers language-none"><code class="language-none">&#x2F;opt&#x2F;arthas # java -jar arthas-boot.jar [INFO] arthas-boot version: 3.1.3[INFO] Found existing java process, please choose one and hit RETURN.* [1]: 7 &#x2F;opt&#x2F;arthas&#x2F;arthas-demo.jar1[INFO] arthas home: &#x2F;opt&#x2F;arthas[INFO] Try to attach process 7[INFO] Attach process 7 success.[INFO] arthas-client connect 127.0.0.1 3658  ,---.  ,------. ,--------.,--.  ,--.  ,---.   ,---.                            &#x2F;  O  \ |  .--. &#39;&#39;--.  .--&#39;|  &#39;--&#39;  | &#x2F;  O  \ &#39;   .-&#39;                          |  .-.  ||  &#39;--&#39;.&#39;   |  |   |  .--.  ||  .-.  |&#96;.  &#96;-.                          |  | |  ||  |\  \    |  |   |  |  |  ||  | |  |.-&#39;    |                         &#96;--&#39; &#96;--&#39;&#96;--&#39; &#39;--&#39;   &#96;--&#39;   &#96;--&#39;  &#96;--&#39;&#96;--&#39; &#96;--&#39;&#96;-----&#39;                                                                                                          wiki      https:&#x2F;&#x2F;alibaba.github.io&#x2F;arthas                                      tutorials https:&#x2F;&#x2F;alibaba.github.io&#x2F;arthas&#x2F;arthas-tutorials                     version   3.1.3                                                                 pid       7                                                                     time      2019-11-13 08:20:51                                                   [arthas@7]$ <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://user-images.githubusercontent.com/38010908/68745453-b484fd00-0631-11ea-84b1-17e6f918ed60.png" alt="image"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;情景模拟&quot;&gt;&lt;a href=&quot;#情景模拟&quot; class=&quot;headerlink&quot; title=&quot;情景模拟&quot;&gt;&lt;/a&gt;情景模拟&lt;/h2&gt;&lt;p&gt;现在有一个很简单的景象，把arthas复制进去，并且运行arthas-demo&lt;/p&gt;
&lt;pre class=&quot;line-n</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
    <category term="docker" scheme="http://example.com/tags/docker/"/>
    
    <category term="arthas" scheme="http://example.com/tags/arthas/"/>
    
    <category term="LinuxThreads" scheme="http://example.com/tags/LinuxThreads/"/>
    
  </entry>
  
  <entry>
    <title>操作系统-页面置换算法</title>
    <link href="http://example.com/2019/10/29/os-page-replace-algorithm/"/>
    <id>http://example.com/2019/10/29/os-page-replace-algorithm/</id>
    <published>2019-10-29T02:11:46.000Z</published>
    <updated>2021-01-27T14:55:21.385Z</updated>
    
    <content type="html"><![CDATA[<p>把选择换出页面的算法称为页面置换算法，置换算法的好坏直接影响到系统的性能。<br>不适当的算法可能回导致进程发生“抖动”，即刚被换出的页很快又被访问，需要将它重新调入，此时又需要再选一页调出。</p><h2 id="最佳置换算法和先进先出置换算法"><a href="#最佳置换算法和先进先出置换算法" class="headerlink" title="最佳置换算法和先进先出置换算法"></a>最佳置换算法和先进先出置换算法</h2><p>下面两种是比较极端的算法，最佳置换算法是一种理想化的算法，具有最好的性能但是实际上无法实现。而先进先出算法是最直观的算法，由于与通常页面的使用规律不符，可能是性能最差的算法。</p><ol><li>最佳置换算法</li></ol><p>选择的淘汰页面将是以后永不使用的，或许是最长时间不再被访问的页面。</p><p><img src="https://user-images.githubusercontent.com/38010908/67646947-5dadd100-f96b-11e9-9c3c-490fb8277e8d.png" alt="image"></p><ol start="2"><li>先进先出算法</li></ol><p>该算法总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面予以淘汰。</p><p><img src="https://user-images.githubusercontent.com/38010908/67646999-9188f680-f96b-11e9-93be-8ab04137326d.png" alt="image"></p><h2 id="最近最久未使用和最少使用置换算法"><a href="#最近最久未使用和最少使用置换算法" class="headerlink" title="最近最久未使用和最少使用置换算法"></a>最近最久未使用和最少使用置换算法</h2><ol><li>LRU(Least Recently Used)置换算法的描述</li></ol><p>LRU页面置换算法是根据页面调入内存后的使用情况作出决策的，LRU是选择最久未使用的页面予以淘汰。<br>该算法赋予每个页面一个访问字段，用来记录一个页面上次被访问以来所经历的时间t。当淘汰一个页面时，选择现有页面中其t值最大的，即最近最久未使用的页面予以淘汰。</p><p><img src="https://user-images.githubusercontent.com/38010908/67647228-74085c80-f96c-11e9-98ac-c199f0c98b0d.png" alt="image"></p><ol start="2"><li>LRU置换算法的硬件支持</li></ol><p>LRU虽然是一种比较好的算法，但要求系统有较多的支持硬件。为了了解一个进程在内存中的各个页面各有多少时间未被进程访问，以及如何快速地知道哪一页是最近最久未使用的页面，须有寄存器和栈两类硬件之一的支持</p><p>1） 寄存器<br>为了记录某进程在内存中各页的使用情况，须为每个在内存中的页面配置一个移位寄存器，可表示为：</p><pre class="line-numbers language-none"><code class="language-none">R&#x3D;Ra-1Ra-2Ra-3···R2R1R0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>当进程访问某物理块时，要将相应寄存器的<code>Ra-1</code>位置设置成1。此时定时信号将没隔一定时间(例如100ms)将寄存器右移一位。</p><blockquote><p>这里可能有点抽象，我理解是如下。就是每隔一段时间，将寄存器右移一位，从R7 -&gt; R6，然后判断对应的页是否被使用，如果使用了则记为1，未使用则记为0，则通过统计这8个寄存器中的记录(R值)，如：<code>00010011</code>跟<code>00000101</code>等总共8个值，明显在<code>00010011</code>跟<code>00000101</code>比较的话，后者比前者小，则说明后者更久未使用</p></blockquote><table><thead><tr><th>时间</th><th>0</th><th>100ms</th><th>200ms</th></tr></thead><tbody><tr><td>页号</td><td>1</td><td>1</td><td>1</td></tr><tr><td>寄存器</td><td>R7:0</td><td>R6:1</td><td>R5:1</td></tr></tbody></table><p>如果把n位寄存器的数看作是一个整数，那么具有最小数值的寄存器所对应的页面就是最近最久未使用的页面。</p><p><img src="https://user-images.githubusercontent.com/38010908/67648028-6bfdec00-f96f-11e9-9100-a0707bc94316.png" alt="image"></p><p>2） 栈<br>利用一个特殊的栈保存当前使用的各个页面的页面号，每当进程访问某页面时，便将该页面的页号从栈中移出，将它压入栈顶。</p><p>假设一进程，分为5个物理块，所访问的页面号序列未：</p><pre class="line-numbers language-none"><code class="language-none">4,7,0,7,1,0,1,2,1,2,6<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>当第四次访问时，因为7已存在在栈中，注意这里的操作是，直接将栈中的7移除了，然后再把第4次访问的7放如栈顶</p></blockquote><p><img src="https://user-images.githubusercontent.com/38010908/67648551-f72bb180-f970-11e9-855d-a74e3934d307.png" alt="image"></p><ol start="3"><li>最少使用(Least Frequently Used, LFU)置换算法</li></ol><p>在LFU算法中采用了移位寄存器方式，刚上面的LRU的访问图完全相同。但是是将<code>Ra-1Ra-2···R2R1</code>求和。</p><blockquote><p>应该指出，这种算法并不能真正反映出页面的使用情况，因为在每一时间间隔内，只是用寄存器的一位来记录页的使用情况，因此，在该时间间隔内，对某页访问一次和访问1000次是完全等效的。</p></blockquote><h2 id="Clock置换算法"><a href="#Clock置换算法" class="headerlink" title="Clock置换算法"></a>Clock置换算法</h2><p>虽然LRU是一种较好的算法，但由于要求比较多的硬件支持，使得其实现所需的成本较高，故实际应用中，大多采用LRU近似算法，Clock算法就是用的比较多的一种LRU近似算法</p><ol><li>简单的Clock置换算法</li></ol><p>为每页设置一位访问位，将内存中的所有页面都通过链接指针连接成一个循环队列，当某页被访问时，其访问位被置1。置换算法在选择一页淘汰时，只需检查页的访问位，如果是0则置换出，如果是1则置为0，再按照FIFO算法检查下一个页面，当其访问位仍为1时，则再返回到队首去检查第一个页面。</p><p>但因为该算法只有一位访问位，只能用它表示该页是否已经使用过，而置换时是将未使用过的页面换出去，故又把该算法成为最近未用算法或NRU(Not Recently Used)算法。</p><p><img src="https://user-images.githubusercontent.com/38010908/67649407-f47e8b80-f973-11e9-912b-4b6d15e75439.png" alt="image"></p><ol start="2"><li>改进型Clock置换算法</li></ol><p>在改进型Clock算法中，除须考虑页面的使用情况外，还需再增加一个因素——置换代价。这样，选择页面置换出时，既要是未使用过的页面，又要是未修改过的页面。</p><p>由访问位A和修改位M可以组合成下面四种类型的页面：</p><ol><li>A=0,M=0, 既最近未访问又没修改过，是最佳的淘汰页</li><li>A=0,M=1，最近未访问，但修改过了，不是很好的淘汰页</li><li>A=1,M=0, 最近已访问过，未修改过，可能再被访问</li><li>A=1,M=1，最近咦访问，且修改过，可能再被访问</li></ol><p>该算法的执行过程可分为以下三步：</p><ol><li>从指针所指示的位置开始，扫描循环队列，寻找A=0且M=0的页，第一次扫描不改变访问位A</li><li>如果第一步失败，继续扫描循环队列，寻找A=0且M=1的页，第二轮扫描期间，将所有扫过的页面访问位设置为0</li><li>如果第二步页失败了，则将指针返回到开始的位置，并将所有的访问位复0，然后重复第一步，如果仍失败，必要时再重复第二步，此时就一定能找到被淘汰的页</li></ol><blockquote><p>该算法与简单Clock算法比较，可减少磁盘的I/O操作次数，但为找到一个可置换的页，可能须经过几轮扫描，换言之，实现该算法本身的开销将有所增加</p></blockquote><h2 id="页面缓冲算法-Page-Buffering-Algorithm-PBA"><a href="#页面缓冲算法-Page-Buffering-Algorithm-PBA" class="headerlink" title="页面缓冲算法(Page Buffering Algorithm, PBA)"></a>页面缓冲算法(Page Buffering Algorithm, PBA)</h2><ol><li>影响页面换进换出效率的若干因素<ol><li>页面置换算法</li><li>写回磁盘的频率</li><li>读入内存的频率</li></ol></li><li>页面缓冲算法PBA</li></ol><p>PBA算法的主要特点是：</p><ol><li>显著降低页面换进、换出的频率，使磁盘I/O操作次数大为减少</li><li>正由于换入换出的开销大幅度减少，才能使其采用一种较简单的置换策略，如FIFO</li></ol><p>为了能显著降低页面换进、换出的频率，在内存中设置了如下两个链表</p><ol><li>空闲页面链表</li></ol><p>该链表是一个空闲物理块链表，是系统掌握的空闲物理块，用于分配给频繁发生缺页的进程，以降低该进程的缺页率。当这样的进程需要读入一个页面时，便可利用空闲物理块链表中的第一个物理块来装入该页。</p><p>当下次再次请求该页面时，不需要再从外存中读入，而直接在该链表中取出</p><ol start="2"><li>修改页链表</li></ol><p>该链表是已修改的页面所形成的链表。跟上述原理几乎一样，只是这个链表用于存放被置换出去已修改的页，这样可以减少写到外存的频率，也可以减低从外存载入到内存的频率。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;把选择换出页面的算法称为页面置换算法，置换算法的好坏直接影响到系统的性能。&lt;br&gt;不适当的算法可能回导致进程发生“抖动”，即刚被换出的页很快又被访问，需要将它重新调入，此时又需要再选一页调出。&lt;/p&gt;
&lt;h2 id=&quot;最佳置换算法和先进先出置换算法&quot;&gt;&lt;a href=&quot;#最</summary>
      
    
    
    
    
    <category term="操作系统" scheme="http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="算法" scheme="http://example.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>操作系统-存储器管理</title>
    <link href="http://example.com/2019/10/29/os-cunchu/"/>
    <id>http://example.com/2019/10/29/os-cunchu/</id>
    <published>2019-10-29T02:09:17.000Z</published>
    <updated>2021-01-27T14:55:21.369Z</updated>
    
    <content type="html"><![CDATA[<h2 id="主存储器与寄存器"><a href="#主存储器与寄存器" class="headerlink" title="主存储器与寄存器"></a>主存储器与寄存器</h2><ol><li>主存储器</li></ol><p>简称内存或主存。</p><ol start="2"><li>寄存器</li></ol><p>寄存器具有与处理机相同的速度，完全能与CPU协调工作。</p><h2 id="程序的装入和连接"><a href="#程序的装入和连接" class="headerlink" title="程序的装入和连接"></a>程序的装入和连接</h2><p>用户程序要在系统中运行，必须先将它装入内存，然后再将其转变为一个可以执行的程序，通常要经过一以下几个步骤。</p><ol><li>编译，由编译程序(Compiler)对用户源程序进行编译，形成若干个目标模块(Object Module)</li><li>链接，由链接程序(Linker)将编译后形成的一组目标模块以及它们所需要的库函数链接在一起，形成一个完整的装入模块(Load Module);</li><li>装入，由装入程序(Loader)将装入模块装入内存</li></ol><p><img src="https://user-images.githubusercontent.com/38010908/67143611-be6c4800-f29f-11e9-87a2-de71d1eaad5c.png" alt="image"></p><h2 id="对换Swapping"><a href="#对换Swapping" class="headerlink" title="对换Swapping"></a>对换Swapping</h2><p><strong>对换的类型</strong><br>每次对换时，都是将一定数量的程序或数据换入或还出内存。根据每次对换时所对换的数量，可将对换分为如下两类：</p><ol><li>整体对换。</li><li>页面(分段)对换。对换的是进程的一个“页面”或“分段”为单位进行的。</li></ol><h3 id="对换空间的管理"><a href="#对换空间的管理" class="headerlink" title="对换空间的管理"></a>对换空间的管理</h3><h3 id="进程的换出与换入"><a href="#进程的换出与换入" class="headerlink" title="进程的换出与换入"></a>进程的换出与换入</h3><ol><li><strong>进程的换出</strong><ol><li>选择被换出的进程。会检查所有驻留在内存中的进程，首先选择处于阻塞或随眠状态的进程，当有多个这样的进程时，应当选择优先级最低的进程作为换出进程。如果系统中已无阻塞进程，而现在的内存空间仍不足以需要，会选择将优先级最低的就绪进程换出。</li><li>进程换出过程。在对换换出时，只能换出非共享的程序和数据段，对于那些共享的程序和数据段，只要有进程需要它，就不能被换出。在进行换出时，应先对申请对换空间，若申请成功，就启动磁盘，将该进程的程序和数据传送到磁盘的对换区上。若传送过程未出现错误，便可回收该进程所占用的内存空间，并对该进程的进程控制块和内存分配表等数据结构做对应的修改。若此时内存中还有可换出的进程，则继续执行换出过程，知道内存中再无阻塞进程为止。</li></ol></li><li><strong>进程的换入</strong><br>先检查PCB集合中所有进程的状态，从中找出“就绪”状态但已换出的进程。当有许多这样的进程时，它将选择其中已换出到磁盘上时间最久的进程作为换入进程，为它申请内存。如果申请成功则直接将进程从外存调入内存，如果失败，则需先将内存中的某些进程换出，腾出足够的内存空间，再将进程调入。</li></ol><h3 id="分页存储管理方式"><a href="#分页存储管理方式" class="headerlink" title="分页存储管理方式"></a>分页存储管理方式</h3><p>根据在离散分配时所分配地址空间的基本单位不同，又可将离散分配分为以下三种：</p><ol><li>分页存储管理方式。将用户程序地址空间分为若干个固定大小的区域，称为“页”或“页面”。</li><li>分段存储管理方式。将用户程序的地址空间分为若干个大小不同的段，每段可定义一组相对完整的信息。</li><li>段页式存储管理方式。将上述两种方式相结合，同时具有两者的优点。</li></ol><h3 id="地址变换机构"><a href="#地址变换机构" class="headerlink" title="地址变换机构"></a>地址变换机构</h3><p>地址变换机构的任务实际上只是将逻辑地址中的页号转换为内存中的物理块号。</p><h4 id="基本的地址变换机构"><a href="#基本的地址变换机构" class="headerlink" title="基本的地址变换机构"></a>基本的地址变换机构</h4><p>当进程要访问某个逻辑地址中的数据时，分为以下几个步骤</p><ol><li>分页地址变换机构自动将有效地址(相对地址)分为页号和页内地址两部分</li><li>对页号与页表长度进行比较，如果页号大于或等于页表长度，则表示本次所访问的地址已超越进程的地址空间</li><li>若为出现越界错误，将页表始址与页号和页表项长度的乘积相加，便得到该表项在页表中的位置</li><li>然后得到该页的物理块号，将之装入物理地址寄存器的块内地址字段中</li></ol><p><img src="https://user-images.githubusercontent.com/38010908/67351335-d8e44100-f57f-11e9-9129-55d6f650c5a9.png" alt="image"></p><h4 id="具有快表的地址变换机构"><a href="#具有快表的地址变换机构" class="headerlink" title="具有快表的地址变换机构"></a>具有快表的地址变换机构</h4><p>其实就是一个缓存而已。</p><p>高速的寄存器，称为“联想寄存器”或“快表”，这个寄存器具备并行查寻能力。  </p><p>当cpu给出有效地址后，将该地址送入联想寄存器即快表，若能直接找到对应的物理地址，直接送入物理地址寄存器中，如果未找到，再到内存中查找，送入物理内存寄存器的同时再将此有效地址跟物理地址的映射存到快表中。如果此时快表已满，则OS必须找到一个老且认为已经不再需要的页表项，将它换出。</p><p><img src="https://user-images.githubusercontent.com/38010908/67352190-eb5f7a00-f581-11e9-9acd-1b31149ab6c7.png" alt="image"></p><p>由于成本关系，快表不可能做的很大，通常只存放16-512个页表项。</p><h2 id="分段存储管理方式"><a href="#分段存储管理方式" class="headerlink" title="分段存储管理方式"></a>分段存储管理方式</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;主存储器与寄存器&quot;&gt;&lt;a href=&quot;#主存储器与寄存器&quot; class=&quot;headerlink&quot; title=&quot;主存储器与寄存器&quot;&gt;&lt;/a&gt;主存储器与寄存器&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;主存储器&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;简称内存或主存。&lt;/p&gt;
&lt;ol star</summary>
      
    
    
    
    
    <category term="操作系统" scheme="http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>操作系统-进程线程</title>
    <link href="http://example.com/2019/10/17/os-process-thread/"/>
    <id>http://example.com/2019/10/17/os-process-thread/</id>
    <published>2019-10-17T02:12:59.000Z</published>
    <updated>2021-01-27T14:55:21.364Z</updated>
    
    <content type="html"><![CDATA[<h2 id="线程与进程的比较"><a href="#线程与进程的比较" class="headerlink" title="线程与进程的比较"></a>线程与进程的比较</h2><ol><li>调度的基本单位</li></ol><p>在传统的OS中，进程是作为独立调度和分派的基本单位，因而进程是能独立运行的基本单位。</p><p>引入线程的OS中，以把线程作为调度和分派的基本单位，因而线程是能独立运行的基本单位。当线程切换时，仅需保存和设置少量的寄存器内容，切换代价远低于进程。</p><ol start="2"><li>并发性</li></ol><p>引入线程的OS中，不仅进程之间可以并发执行，而且一个进程中的多个线程之间亦可并发执行。</p><ol start="3"><li>拥有资源</li></ol><p>进程可以拥有资源，并作为系统中拥有资源的一个基本单位。然而线程本身并不拥有系统资源，而是仅有一点必不可少的、能保证独立运行的资源。</p><p>线程除了拥有自己的少量资源外，还允许多个线程共享该进程所有的资源。</p><ol start="4"><li>独立性</li></ol><p>进程间的独立性比线程间的独立性高的多，这是因为，为了防止进程间彼此干扰和破坏，每个进程都拥有一个独立的地址空间和其它资源，除了共享变量外，不允许其它进程访问。</p><p>但是，同一个进程中的不同线程往往是为了提高并发性以及进行相互之间的合作而创建的，他们共享进程的内存地址空间和资源。</p><ol start="5"><li>系统开销</li></ol><p>在创建或撤销进程时，系统都要为之分配和回收进程控制块、分配或回收其它资源，如内存空间和I/O设备等。类似地，进程切换时，涉及到进程的上下文切换，而线程的切换代价远低于进程。</p><ol start="6"><li>支持多处理机系统</li></ol><p>在多处理机系统中，对于传统的进程，即单线程进程，不管有多少个处理机，该进程只能运行在一个处理机上，但对于多线程进程，可以将一个进程中的多个线程分配到多个处理机上执行。</p><h2 id="线程的状态和线程控制块"><a href="#线程的状态和线程控制块" class="headerlink" title="线程的状态和线程控制块"></a>线程的状态和线程控制块</h2><h3 id="线程运行的三个状态"><a href="#线程运行的三个状态" class="headerlink" title="线程运行的三个状态"></a>线程运行的三个状态</h3><p>与进程一样，各个线程之间也存在共享资源和相互合作的制约关系，致使线程在运行时也具有间断性。所以，线程在运行时具有如下三种基本状态：</p><ol><li>执行状态</li><li>就绪状态</li><li>阻塞状态</li></ol><blockquote><p>线程状态之间的转换和进程之间的转换是一样的</p></blockquote><h3 id="线程控制块TCB"><a href="#线程控制块TCB" class="headerlink" title="线程控制块TCB"></a>线程控制块TCB</h3><p>跟进程控制块(PCB)一样，线程也有这样一个线程控制块TCB。</p><p>如同每个进程有一个进程控制块一样,系统也为每个线程配置了一个线程控制块TCB,将所有用于控制和管理线程的信息记录在线程控制块中。线程控制块通常有这样几项:<br>①线程标识符，为每个线程赋予一个唯一的线程标识符;<br>②一组寄存器，包括程序计数器PC、状态寄存器和通用寄存器的内容;<br>③线程运行状态，用于描述线程正处于何种运行状态:<br>④优先级，描述线程执行的优先程度;<br>⑤线程专有存储区，用于线程切换时存放现场保护信息，和与该线程相关的统计信息等;<br>⑥信号屏蔽，即对某些信号加以屏蔽:<br>⑦堆栈指针，在线程运行时，经常会进行过程调用，而过程的调用通常会出现多重嵌套的情况，这样，就必须将每次过程调用中所使用的局部变量以及返回地址保存起来。  </p><p>为此，应为每个线程设置一个堆栈，用它来保存局部变量和返回地址。相应地，在TCB中，也须设置两个指向堆栈的指针:指向用户自己堆栈的指针和指向核心栈的指针。前者是指当线程运行在用户态时，使用用户自己的用户栈来保存局部变量和返回地址，后者是指当线程运行在核心态时使用系统的核心栈。</p><h2 id="线程的实现"><a href="#线程的实现" class="headerlink" title="线程的实现"></a>线程的实现</h2><ol><li>内核支持线程KST(Kernel Supported Threads)</li><li>用户级线程ULT(User Level Threads)</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;线程与进程的比较&quot;&gt;&lt;a href=&quot;#线程与进程的比较&quot; class=&quot;headerlink&quot; title=&quot;线程与进程的比较&quot;&gt;&lt;/a&gt;线程与进程的比较&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;调度的基本单位&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在传统的OS中，进程是作为独立调度和</summary>
      
    
    
    
    
    <category term="操作系统" scheme="http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="进程" scheme="http://example.com/tags/%E8%BF%9B%E7%A8%8B/"/>
    
    <category term="线程" scheme="http://example.com/tags/%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>操作系统-进程通信</title>
    <link href="http://example.com/2019/10/17/os-process-msg/"/>
    <id>http://example.com/2019/10/17/os-process-msg/</id>
    <published>2019-10-17T02:12:05.000Z</published>
    <updated>2021-01-27T14:55:21.355Z</updated>
    
    <content type="html"><![CDATA[<p>在进程间要传输大量数据时，应当利用OS提供的高级通信工具，该工具的主要特点是</p><ul><li>使用方便。OS隐藏了实现进程通信的具体细节，向用户提供了一组用于实现高级通信的命令(原语)，用户可以方便地直接利用它实现进程之间的通信。</li><li>高效地传送数据。用户可以直接利用高级通信命令(原语)高效地传送大量的数据。</li></ul><h2 id="进程通信的类型"><a href="#进程通信的类型" class="headerlink" title="进程通信的类型"></a>进程通信的类型</h2><p>目前，高级通信机制可归为四大类：共享存储器系统、管道通信系统、消息传递系统以及客户机-服务器系统</p><h3 id="共享存储器系统-Shared-Memory-System"><a href="#共享存储器系统-Shared-Memory-System" class="headerlink" title="共享存储器系统(Shared-Memory System)"></a>共享存储器系统(Shared-Memory System)</h3><p>相互通信的进程共享某些数据结构和共享存储区，进程之间能够通过这些空间进行通信。因此，可以分成以下两种类型：</p><ol><li>基于共享数据结构的通信方式。<br> 操作系统提供共享存储器，由程序员负责对公用数据结构的设置以及对进程间同步的处理。这种通信方式仅适于传递相对少量的数据，通信效率低下，属于低级通信。</li><li>基于共享存储区的通信方式。<br> 为了传输大量数据，在内存中划出了一块共享存储区域，诸进程可通过对该共享区的读或写交换信息，实现通信，数据的形式和位置甚至访问控制都是由进程负责，而不是OS。</li></ol><h3 id="管道-pipe-通信系统"><a href="#管道-pipe-通信系统" class="headerlink" title="管道(pipe)通信系统"></a>管道(pipe)通信系统</h3><p>管道，指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件，又叫pipe文件。<br>为了协调双方的通信，管道机制必须提供以下三方面的协调能力。</p><ol><li>互斥，当一个进程正在对pipe执行读/写操作时，其它进程必须等待</li><li>同步，指当写(输入)进程把一定数量(如4KB)的数据写入pipe，便睡眠等待，直到读(输出)进程取走数据后再把它唤醒。</li><li>确定对方是否存在，只有确定了对方已存在才能进行通信</li></ol><blockquote><p>怎么感觉有点像go的channel呢</p></blockquote><h3 id="消息传递系统-Message-passing-system"><a href="#消息传递系统-Message-passing-system" class="headerlink" title="消息传递系统(Message passing system)"></a>消息传递系统(Message passing system)</h3><p>该机制中，进程不必借助任何共享存储区或数据结构，而是以格式化的消息(message)为单位，将通信的数据封装在消息中，并利用操作系统提供的一组通信命令(原语)，在进程间进行消息传递，完成进程间的数据交换。</p><p>该机制又可以分为两类：</p><ol><li>直接通信方式，指发送进程利用OS所提供的发送原语，直接把消息发送给目标进程</li><li>间接通信方式，指发送和接收进程，都通过共享中间实体(成为邮箱)的方式进行消息的发送和接收，完成进程间的通信。</li></ol><h3 id="客户机-服务器系统-Client-Server-system"><a href="#客户机-服务器系统-Client-Server-system" class="headerlink" title="客户机-服务器系统(Client-Server-system)"></a>客户机-服务器系统(Client-Server-system)</h3><p>在客户机-服务器系统的通信机制下，在网络环境的各种应用领域已成为当前主流的通信实现机制，主要的实现方法分为三类：套接字、远程过程调用、和远程方法调用</p><ol><li>套接字(Socket)</li></ol><p>套接字可以分为两类</p><ul><li>基于文件型。通信原理类似于前面提到的管道</li><li>基于网络型。</li></ul><ol start="2"><li>远程过程调用和远程方法调用</li></ol><p>RPC引入一个存根(stub)的概念：在本地客户端，每个能够独立运行的远程过程都拥有一个客户存根(client stubborn)，本地进程调用远程过程实际是调用该过程关联的存根；与此类似，在每个远程进程所在的服务器端，其所对应的实际可执行进程也存在一个服务器存根(stub)与其关联。本地客户存根与对应的远程服务器存根一般也是处于阻塞状态，等待消息。</p><p>实际上，远程过程调用的主要步骤是：</p><ol><li>本地过程调用者以一般方式调用远程在本地关联的客户存根，传递相应的参数，然后将控制权转移给客户存根；</li><li>客户存根执行，完成包括过程名和调用参数等信息的建立，将控制权转移给本地客户进程；</li><li>本地客户进程完成与服务器的消息传递，将消息发送到远程服务器进程；</li><li>远程服务器进程接收到消息后转入执行，并根据其中的远程过程名找到对应的服务器存根，将消息转给存根；</li><li>该服务器存根接到消息后，由阻塞状态转入执行状态，拆开消息从中取出过程调用的参数，然后以一般方式调用服务器上关联的过程</li><li>在服务器的远程过程运行完毕后，将结果返回给与之关联的服务器存根；</li><li>该服务器存根获得控制权运行，将结果打包为消息，并将控制权转移给远程服务器进程</li><li>远程服务器进程将消息发送回客户端</li><li>本地客户进程接收到消息后，根据其中的过程名将消息存入关联的客户存根，再将控制权转移给客户存根</li><li>客户存根从消息中取出结果，返回给本地调用者进程，并完成控制权的转移</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在进程间要传输大量数据时，应当利用OS提供的高级通信工具，该工具的主要特点是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用方便。OS隐藏了实现进程通信的具体细节，向用户提供了一组用于实现高级通信的命令(原语)，用户可以方便地直接利用它实现进程之间的通信。&lt;/li&gt;
&lt;li&gt;高效地传送数据</summary>
      
    
    
    
    
    <category term="操作系统" scheme="http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="进程" scheme="http://example.com/tags/%E8%BF%9B%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>mysql-表</title>
    <link href="http://example.com/2019/10/16/mysql-table/"/>
    <id>http://example.com/2019/10/16/mysql-table/</id>
    <published>2019-10-16T02:25:15.000Z</published>
    <updated>2021-01-27T14:55:21.376Z</updated>
    
    <content type="html"><![CDATA[<p>表</p><h2 id="行记录格式"><a href="#行记录格式" class="headerlink" title="行记录格式"></a>行记录格式</h2><h3 id="关于text与blob存储空间（Compressed和dynamic行记录格式）"><a href="#关于text与blob存储空间（Compressed和dynamic行记录格式）" class="headerlink" title="关于text与blob存储空间（Compressed和dynamic行记录格式）"></a>关于text与blob存储空间（Compressed和dynamic行记录格式）</h3><p>在Innodb 1.0.x版本开始引入了新的文件格式，以前支持的<code>Compact</code>和<code>Redundant</code>格式称为<code>Antelope</code>文件格式，新的文件格式称为<code>Barracuda</code>文件格式，<code>Barracuda</code>文件格式拥有两种新的行记录格式：<code>Compressed</code>和<code>Dynamic</code>。</p><p>在新的两种记录格式对于放在BLOB中的数据采用了完全的行溢出方式。<br>如下图可知，数据页中只存放20个字节的指针，实际的数据都存放在Off Page中，而之前的<code>Compact</code>和<code>Redundant</code>两种格式会存放768个前缀字节</p><p><img src="https://user-images.githubusercontent.com/38010908/66882671-ec326200-effd-11e9-805d-81f594e6fb78.png" alt="image"></p><blockquote><p><code>Compressed</code>行记录格式的另一个功能就是，存储在其中的行数据会以zlib的算法进行压缩，因此对于BLOB、TEXT、VARCHAR这类大长度类型的数据能够进行非常有效的存储</p></blockquote><h2 id="char行结构存储"><a href="#char行结构存储" class="headerlink" title="char行结构存储"></a>char行结构存储</h2><p>在多字节字符集类型下，char类型被明确视为变长字符类型，对于未能占满长度的字符还是填充0x20。</p><blockquote><p>在多字节字符集的情况下，CHAR和VARCHAR的实际行存储基本是没有区别的。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;表&lt;/p&gt;
&lt;h2 id=&quot;行记录格式&quot;&gt;&lt;a href=&quot;#行记录格式&quot; class=&quot;headerlink&quot; title=&quot;行记录格式&quot;&gt;&lt;/a&gt;行记录格式&lt;/h2&gt;&lt;h3 id=&quot;关于text与blob存储空间（Compressed和dynamic行记录格式）&quot;&gt;&lt;a</summary>
      
    
    
    
    
    <category term="mysql" scheme="http://example.com/tags/mysql/"/>
    
    <category term="innodb" scheme="http://example.com/tags/innodb/"/>
    
  </entry>
  
  <entry>
    <title>操作系统-经典进程同步问题</title>
    <link href="http://example.com/2019/10/15/os-process-sync-problem/"/>
    <id>http://example.com/2019/10/15/os-process-sync-problem/</id>
    <published>2019-10-15T06:27:32.000Z</published>
    <updated>2021-01-27T14:55:21.357Z</updated>
    
    <content type="html"><![CDATA[<h1 id="经典进程同步问题"><a href="#经典进程同步问题" class="headerlink" title="经典进程同步问题"></a>经典进程同步问题</h1><p>关于进程同步有一系列经典问题，比较代表性的有</p><ul><li>生产者——消费者</li><li>读者——写者</li><li>哲学家进餐问题</li></ul><h2 id="生产者——消费者问题"><a href="#生产者——消费者问题" class="headerlink" title="生产者——消费者问题"></a>生产者——消费者问题</h2><ol><li>利用记录型信号量解决生产者-消费者问题</li></ol><p>假定生产者消费者之间的公用缓冲池具有n个缓冲区，互斥信号量mutex实现诸进程对缓冲池的互斥使用，empty、full表示缓冲池中空缓冲区和满缓冲区的数量。</p><p>假设：缓冲池未满，生产者可将消息送入缓冲池；缓冲池未空，消费者则可以从缓冲池取走一个消息。</p><pre class="line-numbers language-c" data-language="c"><code class="language-c">&#x2F;&#x2F; in为进队列的下标，out为消费队列的下标int in&#x3D;0,out&#x3D;0;&#x2F;&#x2F; 循环队列item buffer[n];&#x2F;&#x2F; mutex互斥锁，empty：剩余可用的队列空间，full当前已有的产品数量semaphore mutex&#x3D;1,empty&#x3D;n,full&#x3D;0;void proceducer()&#123;    do&#123;        &#x2F;&#x2F; 生产了一个产品nextp        producer an item nextp;        ...        &#x2F;&#x2F; 如果是empty为0，则进程会被放进等待的队列中        wait(empty);        &#x2F;&#x2F; 获得一个锁的东西，比如此时有消费者在buffer中获取产品，则也会被放进等待队列中，直到被释放        wait(mutex);        &#x2F;&#x2F; 已取得锁，可以将产品放进in的位置        buffer[in]&#x3D;nextp;           &#x2F;&#x2F; 将该buffer当循环队列使用，计算下次放进去队列的下标        in:&#x3D;(in+1)%n;        &#x2F;&#x2F; 释放该锁，使消费者可以获得该互斥锁        signal(mutex);        &#x2F;&#x2F; full表示有多少个产品，signal表示对full++，此时多了一个产品，则唤醒(通知)在等待队列中的消费者可以进行消费了        signal(full);    &#125;while(true);&#125;void consumer()&#123;    do &#123;        &#x2F;&#x2F; 判断队列是否为空，为空则将进程放进阻塞队列中，直到proceducer()有新的产品被生产了，然后通知该阻塞的队列的进程，也就本进程了        wait(full);        &#x2F;&#x2F; 获取操作队列的锁        wait(mutex);        &#x2F;&#x2F; 获取产品        nextc&#x3D;buffer[out];        &#x2F;&#x2F; 循环队列，获取下一个出队列的下标        out&#x3D;(out+1)%n;        &#x2F;&#x2F; 释放队列的锁，通知生产者可以操作队列了        signal(mutex);        &#x2F;&#x2F; empty++，队列增加了一个位置，通知生产在阻塞队列的进程可以生产了         signal(empty);        &#x2F;&#x2F; 消费。。        consumer the item in nextc;    &#125; while(true);&#125;&#x2F;&#x2F; main void main()&#123;    cobegin        proceducer(); consumer();    coend&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>利用AND信号量解决生存者-消费者问题  </li></ol><p>几乎与上述描述一致，这里用AND信号量解决</p><pre class="line-numbers language-c" data-language="c"><code class="language-c">&#x2F;&#x2F; in为进队列的下标，out为消费队列的下标int in&#x3D;0,out&#x3D;0;&#x2F;&#x2F; 循环队列item buffer[n];&#x2F;&#x2F; mutex互斥锁，empty：剩余可用的队列空间，full当前已有的产品数量semaphore mutex&#x3D;1,empty&#x3D;n,full&#x3D;0;void proceducer()&#123;    do&#123;        &#x2F;&#x2F; 创建新产品        producer an item nextp;        &#x2F;&#x2F; AND信号量，这里复习一下Swait是什么        &#x2F;&#x2F; 一个死循环，然后判断是否所有条件都满足(大于等于1)，只要有其中一个条件不满足，就会将该进程放进等待或者阻塞队列中        &#x2F;&#x2F; 当满足条件了，会对swait中的参数进行减一操作，对empty减一，就是空闲数-1        Swait(empty,mutex);        &#x2F;&#x2F; 把新生产的产品放进去队列        buffer[in]&#x3D;nextp;        &#x2F;&#x2F; 计算下标        in:&#x3D;(in+1)%n;        &#x2F;&#x2F; AND信号量的操作，也复习一下        &#x2F;&#x2F; 对Ssignal中的所有参数进行加一操作        &#x2F;&#x2F; 并唤醒等待或阻塞的进程        Ssignal(mutex,full);    &#125; while(true);&#125;void consumer()&#123;    do &#123;        &#x2F;&#x2F; 上述一样，当full(未消费的产品数)大于等于1        &#x2F;&#x2F; 且mutex互斥锁没有被占用时        &#x2F;&#x2F; 取得资源的使用权，否则阻塞        Swait(full,mutex);        nextc&#x3D;buffer[out];        out&#x3D;(out+1)%n;        &#x2F;&#x2F; 对mutex跟empty进行加一操作，表示释放资源        &#x2F;&#x2F; 并且唤醒在等待empty跟mutex的进程        Ssignal(mutex,empty);        consumer the item in nextc;    &#125;while(true);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>利用管程</li></ol><p>在利用管程方法来解决生产者—消费者的问题时，首先为他们建立一个管程，并命名为producerconsumer，简称pc，其中包含两个过程</p><ol><li>put(x)过程。将产品放进去缓冲池中，需要count&lt;=N</li><li>get(x)过程。从缓冲池中取出一个产品，需要count&gt;1</li></ol><p>对于条件变量notfull和notempty，分别有两个过程cwait和csignal对它们进行操作</p><ol><li>cwait(condition)过程：当管程被一个进程占用时，其它进程调用该过程时阻塞，并挂在condition的队列上</li><li>csignal(condition)过程：唤醒在cwait执行后阻塞的条件condition队列上的进程，如果进程不止一个，则选择其中一个唤醒，队列为空则无操作返回</li></ol><pre class="line-numbers language-c" data-language="c"><code class="language-c">Monitor producerconsumer&#123;    item buffer[N];    int in,out;    &#x2F;&#x2F; 条件变量    &#x2F;&#x2F; notfull，没有空余的区域    &#x2F;&#x2F; notempty，队列为空    condition notfull,notempty;    int count;    public:    void put(item x)&#123;        &#x2F;&#x2F; 当队列中的数据以达到最大值        &#x2F;&#x2F; 则将本进程放进等待队列中阻塞        if(count&gt;&#x3D;N)cwait(notfull);        buffer[in]&#x3D;x;        in&#x3D;(in+1)%N;        count++;        &#x2F;&#x2F; 唤醒队列其中一个进程可以进行消费了        csignal(notempty);    &#125;    void get(item x)&#123;        &#x2F;&#x2F; 当队列没有数据时        &#x2F;&#x2F; 将进程放进等待数据的队列中阻塞        if(count&lt;&#x3D;0)cwait(notempty);        x&#x3D;buffer[out];        out&#x3D;(out+1)%N;        count--;        &#x2F;&#x2F; 当数据被消费了        &#x2F;&#x2F; 通知被阻塞的生产者可以继续生产了        csignal(notfull);    &#125;    &#x2F;&#x2F; init    &#123;   in&#x3D;0;out&#x3D;0;count&#x3D;0; &#125;&#125;PC;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在利用管程解决生产者-消费者时，其中的生产者消费者可描述为：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c">void producer()&#123;    item x;    while(true)&#123;        produce an item in nextp;        PC.put(x);    &#125;&#125;void consumer()&#123;    item x;    while(true)&#123;        PC.get(x);        consume the item in nextc;    &#125;&#125;void main()&#123;    cobegin;    producer(); consumer();    coend;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="哲学家进餐问题"><a href="#哲学家进餐问题" class="headerlink" title="哲学家进餐问题"></a>哲学家进餐问题</h2><h3 id="利用记录型信号量解决问题"><a href="#利用记录型信号量解决问题" class="headerlink" title="利用记录型信号量解决问题"></a>利用记录型信号量解决问题</h3><p>可以用一个信号量表示一只筷子，五个信号量构成一个数组</p><pre class="line-numbers language-none"><code class="language-none">semaphore chopstick[5]&#x3D;&#123;1,1,1,1,1&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-c" data-language="c"><code class="language-c">do&#123;    &#x2F;&#x2F; 拿左手边的筷子，如果没有则阻塞    wait(chopstick[i]);    &#x2F;&#x2F; 拿右手边的筷子，如果没有则阻塞    wait(chopstick[(i+1)%5];        &#x2F;&#x2F; 拿到筷子了，吃饭。。        &#x2F;&#x2F; 释放左手边的筷子    signal(chopstick[i]);    &#x2F;&#x2F; 释放右手边的筷子    signal(chopstick[(i+1)%5];&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上述解法可保证不会有两个相邻的哲学家同时进餐，但却有可能引起死锁。假如五位哲学家同时极饿而各自拿起左边的筷子时，都将因为无筷子可拿而无限期地等待。对于这样的死锁问题，可采取一下几种解决方法：</p><ol><li>至多只允许有四位哲学家同时去拿左边的筷子，最终能保证至少有一位哲学家能够进餐，并在用完时能释放他用过的两只筷子，从而使更多的哲学家能够进餐</li><li>仅当哲学家的左、右两只筷子均可用时，才允许他拿起筷子进餐</li><li>规定奇数号哲学家先拿他左边的筷子，然后再去拿右边的筷子，而偶数号哲学家则相反。按照这规定，将是1、2号哲学家竞争1号筷子，3、4号竞争3号筷子。即五位哲学家都先竞争奇数号筷子，获得后再去竞争偶数号筷子，最后总有一位哲学家能获得两只筷子而进餐。</li></ol><h3 id="利用AND信号量机制"><a href="#利用AND信号量机制" class="headerlink" title="利用AND信号量机制"></a>利用AND信号量机制</h3><p>从上述可以知道，第二个解决方案</p><blockquote><ol start="2"><li>仅当哲学家的左、右两只筷子均可用时，才允许他拿起筷子进餐</li></ol></blockquote><pre class="line-numbers language-c" data-language="c"><code class="language-c">semaphore chopstick chopstick[5]&#x3D;&#123;1,1,1,1,1&#125;do &#123;    ...    &#x2F;&#x2F; think    ...    Sswait(chopstick[(i+1)%5],chopstick[i]);    &#x2F;&#x2F; eat    ...    Ssignal(chopstick[(i+1)%5],chopstick[i]);&#125; while(true)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="读者-写者问题"><a href="#读者-写者问题" class="headerlink" title="读者-写者问题"></a>读者-写者问题</h2><p>也就是对某个文件进行read,write操作，read操作可以多个进程同时执行，但是write只能允许一个进程执行并且此时不允许read操作以及write操作，否则回引起混乱</p><h3 id="利用记录型信号量解决问题-1"><a href="#利用记录型信号量解决问题-1" class="headerlink" title="利用记录型信号量解决问题"></a>利用记录型信号量解决问题</h3><p>为实现reader与writer进程间在读或写时的互斥信号量<code>Wmutex</code>。另外，再设置一个整形变量<code>Readcount</code>表示正在读的进程数目，由于只要有一个reader进程在读，就不允许writer进程去写。因此，仅当readcount=0,reader进程才需要执行wait(wmutex)操作。当reader执行了readcount减1的操作后其值为0时，才需要执行signal(Wmutex)，以便让writer进程写操作。因为readcount是一个临界值，所以需要设置一个互斥锁rmutex</p><blockquote><p>注意⚠️：这里注意两个信号量，<code>rmutex</code>表示对<code>readcount</code>临界资源的互斥锁，而<code>wmutex</code>表示对被读写的资源的一个互斥锁</p></blockquote><pre class="line-numbers language-c" data-language="c"><code class="language-c">&#x2F;&#x2F; 两个信号量semaphore rmutex&#x3D;1,wmutex&#x3D;1;&#x2F;&#x2F; 记录获得读锁的进程数int readcount&#x3D;0;void reader()&#123;    do&#123;        &#x2F;&#x2F; 阻塞等待readcount的互斥锁        wait(rmutex);        &#x2F;&#x2F; 当readcount为0时，代表没有进程在进行读操作        &#x2F;&#x2F; 那么有可能此时该资源正在被写        &#x2F;&#x2F; 所以需要等待该资源的锁        if(readcount&#x3D;&#x3D;0) wait(wmutex);        &#x2F;&#x2F; 获得资源的锁后，说明写操作已经结束了        &#x2F;&#x2F; 可以进行一些操作了        &#x2F;&#x2F; 对readcount++操作，表示此时多了一个进程进行读操作        readcount++;        &#x2F;&#x2F; 此时可以将rmutex锁释放了        &#x2F;&#x2F; 因为同一时间可以有多个进程进行读操作        &#x2F;&#x2F; 若没有释放rmutex锁的话        &#x2F;&#x2F; 别的进程则无法获取到该锁        &#x2F;&#x2F; 进而退化成，读操作也是互斥了的        signal(rmutex);        &#x2F;&#x2F; ..读操作                &#x2F;&#x2F; ..读完        &#x2F;&#x2F; 读完之后获取readcount锁        &#x2F;&#x2F; 因为需要对readcount进行减1的操作        wait(rmutex);        readcount--;        &#x2F;&#x2F; 如果当没有进程在读时，那么可以释放该资源的互斥锁了        &#x2F;&#x2F; 因为只要有1个进程在读，那么就无法进行写操作        &#x2F;&#x2F; 所以当readcount为0时，则可以释放该锁        &#x2F;&#x2F; 便可以唤醒writer进程，进行写操作        if(readcount&#x3D;&#x3D;0) signal(wmutex);        &#x2F;&#x2F; 对readcount--完后，就可以释放该锁了        signal(rmutex);    &#125;while(true);&#125;&#x2F;&#x2F; writer进程void writer()&#123;    do&#123;        &#x2F;&#x2F; 等待该资源的互斥锁        wait(wmutex);        &#x2F;&#x2F; .. 写操作        &#x2F;&#x2F; 释放        signal(wmutex);    &#125;while(true);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="利用信号量集机制解决读者-写者问题"><a href="#利用信号量集机制解决读者-写者问题" class="headerlink" title="利用信号量集机制解决读者-写者问题"></a>利用信号量集机制解决读者-写者问题</h3><p>这里与上述的问题不同，它增加了一个限制，最多只允许RN个读者同时读，为此又引入一个信号量L，并赋予其初值RN，通过执行<code>wait(L,1,1)</code>操作来控制读者的数目，每当有一个读者进入时，要先执行<code>wait(L,1,1)</code>操作，使L的值减1。当有RN个读者进入读后，L便减为0，当第RN+1个读者想要进入读时，则会阻塞。</p><blockquote><p>RN: 表示限制的读进程数<br>mux: 表示对资源的写锁</p></blockquote><pre class="line-numbers language-c" data-language="c"><code class="language-c">int RN;semaphore L&#x3D;RN,mx&#x3D;1;void reader()&#123;    do&#123;        &#x2F;&#x2F; 获取读锁        &#x2F;&#x2F; 读锁资源总共L个，一次最少获取资源1个，本次获取1个资源        Swait(L,1,1);        &#x2F;&#x2F; 这里表示所有进程都可以获取锁        &#x2F;&#x2F; mx--        Swait(mx,1,0);        &#x2F;&#x2F; 读操作...        &#x2F;&#x2F; 释放资源        Ssignal(L,1);    &#125;while(true);&#125;void writer()&#123;    do&#123;        &#x2F;&#x2F; 等待读锁，获取全部的读资源锁        Swait(mx,1,1,L,RN,0);        &#x2F;&#x2F; 写操作...        &#x2F;&#x2F; 写完释放写锁        Ssignal(mx,1);    &#125;while(true);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p><code>Swait(S,1,0)</code>当S&gt;=1时，允许多个进程进入某特定区，当S变为0后，则阻止任何进程进入特定区</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;经典进程同步问题&quot;&gt;&lt;a href=&quot;#经典进程同步问题&quot; class=&quot;headerlink&quot; title=&quot;经典进程同步问题&quot;&gt;&lt;/a&gt;经典进程同步问题&lt;/h1&gt;&lt;p&gt;关于进程同步有一系列经典问题，比较代表性的有&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;生产者——消费者&lt;/</summary>
      
    
    
    
    
    <category term="操作系统" scheme="http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="进程" scheme="http://example.com/tags/%E8%BF%9B%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>操作系统-进程</title>
    <link href="http://example.com/2019/10/11/os-process/"/>
    <id>http://example.com/2019/10/11/os-process/</id>
    <published>2019-10-11T03:21:29.000Z</published>
    <updated>2021-01-27T14:55:21.368Z</updated>
    
    <content type="html"><![CDATA[<h1 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h1><p>为了提高资源利用率和系统吞吐量，通常采用多道程序技术，将多个程序同时装进内存，并使之并发运行，此时作为资源分配和独立运行的基本单位都是进程。</p><h2 id="程序并发执行时的特征"><a href="#程序并发执行时的特征" class="headerlink" title="程序并发执行时的特征"></a>程序并发执行时的特征</h2><ul><li>间断性。程序在并发时，由于它们共享系统资源，以及为完成同一项任务而相互合作，致使这些并发成执行的程序之间形成了相互制约的关系。相互制约将导致并发程序具有“执行——暂停——执行”这种间断性的活动规律</li><li>失去封闭性。</li><li>不可再现性</li></ul><h2 id="进程的描述"><a href="#进程的描述" class="headerlink" title="进程的描述"></a>进程的描述</h2><p>为了使参与并发执行的每个程序(含数据)都能独立地运行，操作系统中必须为止配置一个专门的数据结构，称为进程控制块(Process Control Block, PCB)。系统利用PCB来描述进程的基本情况和活动过程，进而控制和管理进程。</p><blockquote><p>一般情况下，我们把进程实体就简称为进程，例如，所谓创建进程，实质上是创建进程实体中的PCB；而撤销进程，实质上是撤销进程的PCB。</p></blockquote><p>较为典型的进程定义：</p><ol><li>进程是程序的一次执行</li><li>进程是一个程序及其数据在处理机上顺序执行时所发生的活动</li><li>进程是具有独立功能的程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位</li></ol><p>进程的特征</p><ol><li>动态性。进程的实质是进程实体的执行过程，因此，动态性是进程的最基本特征。动态性还表现在“它由创建而产生，由调度而执行，由撤销而消亡”，可见进程实体具有一定的生命周期。</li><li>并发性。是指多个进程实体同存于内存中，且能在一段时间内同时运行。</li><li>独立性。实体是一个能独立运行、独立获得资源和独立接受调度的基本单位。凡未建立PCB的程序都不能作为一个独立的单位参与运行</li><li>异步性。是指进程是按异步方式运行的，即按各自独立的、不可预知</li></ol><h2 id="进程的基本状态及转换"><a href="#进程的基本状态及转换" class="headerlink" title="进程的基本状态及转换"></a>进程的基本状态及转换</h2><p>由于多个进程在并发时共享系统资源，致使它们在运行过程中呈现间断性的运行规律，所以进程在其生命周期内可能具有多种状态。一般而言，每一个进程至少应处以下三种基本状态之一</p><ol><li>就绪(Ready)状态。指这些进程已处于准备好运行的状态，即进程已分配除CPU意外的所有必要资源后，只要再获得CPU便可立即执行。</li><li>执行(Running)状态。指进程以获得CPU，其程序正在执行的状态。</li><li>阻塞(Block)状态。这是指正在执行的进程由于发生某事件(如I/O请求、申请缓冲区失败等)暂时无法继续执行的状态，亦即进程的执行收到阻塞。</li></ol><h3 id="三种基本状态转换"><a href="#三种基本状态转换" class="headerlink" title="三种基本状态转换"></a>三种基本状态转换</h3><p><img src="https://user-images.githubusercontent.com/38010908/66402828-17beb680-ea18-11e9-8714-d4da0eaea79e.png" alt="image"></p><h3 id="创建状态和终止状态"><a href="#创建状态和终止状态" class="headerlink" title="创建状态和终止状态"></a>创建状态和终止状态</h3><p>为了满足进程控制块对数据及操作的完整性要求以及增强管理的灵活性，通常在系统中又为进程引入两种常见的状态：创建状态和终止状态。</p><ol><li>创建状态<br>如果因为资源不足等情况，创建该进程的资源不能地到满足，如系统无足够的内存使进程无法装入其中，此时创建工作尚未完成，进程不能被调度运行，于是把此时进程所在的状态称为创建状态</li><li>终止状态<br>进程的终止也要分两个步骤：首先是等待操作系统进行善后处理，最后将其PCB清零，并将PCB空间返还给系统。当一个进程被各种情况终止了，它将进入终止状态。进入终止状态的进程以后不能再执行，但在操作系统中依然保留一个记录，保存状态码和一些计时统计数据，供其他进程收集，一旦其他进程完成了对其信息的提取之后，操作系统将删除该进程，将PCB清零并将该空白的PCB返还给操作系统。</li></ol><p>进程五种基本状态及转换</p><p><img src="https://user-images.githubusercontent.com/38010908/66403599-6d479300-ea19-11e9-84b1-d70a16b0820c.png" alt="image"></p><h2 id="挂起操作和进程状态的转换"><a href="#挂起操作和进程状态的转换" class="headerlink" title="挂起操作和进程状态的转换"></a>挂起操作和进程状态的转换</h2><p>除了三种基本状态外，还引入了一个对进程重要的操作——挂起操作。当该操作作用于某个进程时，该进程将被挂起，意味着此时进程处于静止状态。如果进程正在执行，它将暂停执行。若原本处于就绪状态，则该进程此时暂不接受调度。与挂起操作对应的操作时激活操作。</p><h3 id="引入原语操作后的三个进程状态的转换"><a href="#引入原语操作后的三个进程状态的转换" class="headerlink" title="引入原语操作后的三个进程状态的转换"></a>引入原语操作后的三个进程状态的转换</h3><ul><li>挂起原语(suspend)</li><li>激活原语(active)</li></ul><p>在上述两个原语操作的作用下，可能发生以下几种状态转换</p><ol><li>活动就绪(Readya) –&gt; 静止就绪(Readys)，当处于readya时，进程可以接受调度，但出于readys时，不再被调度执行</li><li>活动阻塞(Blockeda) –&gt; 静止阻塞(Blockeds)，处于Blockeds状态的进程在其所期待的事件出现后，从静止阻塞(blockeds)变为静止就绪(readys)状态</li><li>静止就绪(readys) –&gt; 活动就绪(readya)，处于readys状态的进程若用激活原语active激活后，该进程转变为readya状态</li><li>静止阻塞(blockeds) –&gt; 活动阻塞(blockeda)，处于blockeds状态的进程若用激活原语active激活后，进程将转变为blockeda状态</li></ol><p><img src="https://user-images.githubusercontent.com/38010908/66405675-0d52eb80-ea1d-11e9-9a79-8851bfad84bb.png" alt="image"></p><h3 id="引入挂起操作后五个进程状态的转换"><a href="#引入挂起操作后五个进程状态的转换" class="headerlink" title="引入挂起操作后五个进程状态的转换"></a>引入挂起操作后五个进程状态的转换</h3><ol><li>NULL –&gt; 创建： 一个新进程产生时，该进程处于创建状态</li><li>活动 –&gt; 活动就绪： 当前系统的性能和内存容量均允许的情况下，完成对进程创建的必要操作后，将状态转换为就绪状态</li><li>创建 –&gt; 静止就绪： 当资源不足以分配给该进程时，主要是主存，系统会将进程状态转为静止就绪状态，被安置在外存，不参与调度，此时进程创建尚未完成</li><li>执行 –&gt; 终止：当进程以任意形式终结时，该进程被转换为终止状态。</li></ol><p><img src="https://user-images.githubusercontent.com/38010908/66406698-a0d8ec00-ea1e-11e9-89ce-ba9a01dc31de.png" alt="image"></p><h2 id="进程管理中的数据结构"><a href="#进程管理中的数据结构" class="headerlink" title="进程管理中的数据结构"></a>进程管理中的数据结构</h2><p>OS管理资源、进程等数据结构一般分为以下四类：内存表、设备表、文件表和用于进程管理的进程表，通常进程表又被称为进程控制块PCB。</p><h3 id="进程控制块PCB的作用"><a href="#进程控制块PCB的作用" class="headerlink" title="进程控制块PCB的作用"></a>进程控制块PCB的作用</h3><p>为了便于系统描述和管理进程的运行，在OS的核心为每个进程专门定义了一个数据结构——进程控制块PCB(Process Control Block)。PCB作为进程实体的一部分，记录了操作系统所需的，用于描述进程的当前情况以及管理进程运行的全部信息，是操作系统中最重要的记录型数据结构。</p><p>PCB具体作用的阐述：</p><ol><li>作为独立运行的基本单位的标志。当一个程序(含数据)配置了PCB后，就表示它已是一个能在多道程序环境下独立运行的、合法的基本单位，也就具有取得OS服务的权利。系统是通过PCB感知进程的存在的，事实上，PCB已成为进程存在于系统中的唯一标志</li><li>能实现间断性运行方式。在多道程序环境下，程序是采用停停走走间断性的运行方式运行的。在有了PCB之后，系统将CPU现场信息保存在被中断的进程的PCB中，供该进程再次被调度执行时恢复CPU现场时使用。</li><li>提供进程管理所需要的信息。当调度程序调度到某进程运行时，该程序所需要的资源信息都需要到PCB中获取。</li><li>提供进程调度所需要的信息。PCB提供了进程处于何种状态的信息，调度需要根据该信息进行调度，比如只有处于就绪状态才能被调度。</li><li>实现与其他进程同步与通信。进程同步机制是用于实现多个进程的协调运行的，在采用信号量机制时，它要求每个进程中都设置有相应的用于同步的信号量。在PCB中还具有用于实现进程通信的区域或通信队列指针等。</li></ol><p>进程控制块PCB的组织方式  </p><ol><li>线性方式</li><li>链接方式</li><li>索引方式</li></ol><h2 id="进程控制"><a href="#进程控制" class="headerlink" title="进程控制"></a>进程控制</h2><p>进程控制一般是由内核中的原语来实现的。</p><h3 id="进程的阻塞与唤醒"><a href="#进程的阻塞与唤醒" class="headerlink" title="进程的阻塞与唤醒"></a>进程的阻塞与唤醒</h3><p>引起进程阻塞和唤醒的时间</p><ol><li>向系统请求共享资源失败</li><li>等待某种操作的完成。比如等待某I/O设备完成指定的任务，该进程才能继续执行，则该进程在启动了I/O设备之后就自动进入阻塞状态了。</li><li>新数据尚未到达。对于相互合作的进程，如果一个进程需要先获得另一进程提供的数据后才能对该数据进行处理，只要其所需数据尚未到达，进程便只有阻塞。</li><li>等待新任务的到达。</li></ol><p>进程的阻塞过程<br>正在执行的进程，如果发生了上述某时间，进程便通过调用阻塞原语block将自己阻塞。可见阻塞是进程自身的一种主动行为。<br>进入阻塞的过程</p><blockquote><p>调用block –&gt; 将PCB状态改为阻塞 –&gt; 将PCB插入阻塞队列</p></blockquote><p>进程唤醒过程<br>当被阻塞进程所期待的事情发生时，比如它所启动的I/O操作已完成，或其所期待的数据已经到达，则由有关进程(不如提供数据的进程)调用唤醒原语<code>wakeup</code>，将等待该事件的进程唤醒。<br>被唤醒的过程  </p><blockquote><p>将被阻塞的进程从等待该事件的阻塞队列中移出 –&gt; 将PCB状态改为就绪 –&gt; 将该PCB插入到就绪队列中</p></blockquote><h3 id="进程的挂起与激活"><a href="#进程的挂起与激活" class="headerlink" title="进程的挂起与激活"></a>进程的挂起与激活</h3><p>挂起<br>OS利用挂起原语<code>suspend</code>将指定进程或处于阻塞状态的进程挂起。</p><p>激活<br>利用原语<code>active</code>，将指定进程激活。激活原语先将进程从外存调入内存，检查该进程的现行状态，若是静止就绪，将之改为活动就绪。</p><h2 id="进程同步"><a href="#进程同步" class="headerlink" title="进程同步"></a>进程同步</h2><p>单处理机系统中的进程同步机制——硬件同步机制、信号量机制、管程机制等。</p><h3 id="临界区"><a href="#临界区" class="headerlink" title="临界区"></a>临界区</h3><p>每个进程中访问临界资源的那段代码称为临界区。若能保证诸进程互斥地进入自己地临界区，便可实现诸进程对临界资源地互斥访问。<br>为此，每个进程进入临界区之前，应先对欲访问的临界资源进行检查，看它是否正被访问。</p><p>在临界区前面增加一段用于进行检查的代码称为进入区(entry section)，相应的，在临界区后面也要加上一段称为退出区(exit section)的代码。</p><p>一个访问临界资源的循环过程描述如下：</p><pre class="line-numbers language-none"><code class="language-none">while(TRUE)&#123;    进入区    临界区    退出区    剩余区&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>所有同步机制应遵循下述四条准则</p><ol><li>空闲让进。当无进程处于临界区时，表明资源处于空闲状态，并允许一个请求立即进入临界区。</li><li>忙则等待。当临界资源被访问时，其他试图进入临界区的进程必须等待。</li><li>有限等待。对要求访问临界资源的进程，应保证在有限时间内能进入自己的临界区，避免“死等”状态。</li><li>让权等待。当进程不能进入自己的临界区时，应立即释放处理机，以避免陷入“忙等”状态。</li></ol><h3 id="硬件同步机制"><a href="#硬件同步机制" class="headerlink" title="硬件同步机制"></a>硬件同步机制</h3><ol><li>关中断<br>进入锁之前关闭中断，那样就确保了只有一个进程在允许，进程无法被调度。有很多缺点：滥用关中断权利可能导致严重后果，关中断时间过长影响系统效率等。</li><li>利用Test-and-Set指令实现互斥<br>这是一种借助一条硬件指令——“测试并建立”指令实现互斥的方法。TS指令一般性描述如下  <pre class="line-numbers language-none"><code class="language-none">boolean TS(boolean *lock)&#123;    Boolean old;    old &#x3D; *lock;    *lock &#x3D; TRUE;    return old;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>这条指令的执行过程是不可分割的，即是一条原语。其中lock有两种状态，当为FALSE时表示该资源空闲，当为TRUE时，表示该资源正在被使用</li></ol><p>利用TS指令实现互斥的循环进程结构可描述如下</p><pre class="line-numbers language-none"><code class="language-none">do &#123;    &#x2F;&#x2F; ...    while TS(&amp;lock); &#x2F;&#x2F; 进入区    critical section; &#x2F;&#x2F; 临界区    lock :&#x3D; FALSE; &#x2F;&#x2F; 退出区    remainder section; &#x2F;&#x2F; 剩余区&#125;while(TRUE)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>利用swap指令实现进程互斥</li></ol><p>对换指令</p><pre class="line-numbers language-c" data-language="c"><code class="language-c">void swap(boolean *a, boolean *b)&#123;    boolean temp;    temp &#x3D; *a;    *a &#x3D; *b;    *b &#x3D; temp;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>用对换指令可以简单有效地实现互斥，方法是为每个临界资源设置一个全局的布尔变量lock，其初值为false，在每个进程中再利用一个局部布尔变量key。利用swap指令实现进程互斥的循环进程可描述如下：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c">do&#123;    key&#x3D;TRUE;    do&#123;        swap(&amp;lock,&amp;key);    &#125;while(key!&#x3D;FALSE);    &#x2F;&#x2F; 临界区操作;    lock&#x3D;FALSE;    &#x2F;&#x2F; ...&#125; while(TRUE);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="信号量机制"><a href="#信号量机制" class="headerlink" title="信号量机制"></a>信号量机制</h3><ol><li>整形信号量</li></ol><p>整形S仅能通过两个标准的原子操作wait(S)和signal(S)来访问</p><pre class="line-numbers language-none"><code class="language-none">wait(S)&#123;    while(S&lt;&#x3D;0);    S--;&#125;signal(S)&#123;    S++;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>记录型信号量</li></ol><p>在整型信号量机制中的wait操作，只要是信号量S&lt;=0,就会不断测试，因此该机制并未遵循“让权等待”的准则，处于“忙等”状态。</p><p>记录型信号量机制采取了“让权等待”的策略，会出现多个进程等待访问一个临界资源的情况，为此信号量机制除了用于代表数目的整型变量value外，还应增加一个进程链表指针list，用于链接上述的所有等待进程</p><pre class="line-numbers language-c" data-language="c"><code class="language-c">typedef struct&#123;    int value;    struct process_controller_block *list;&#125;semaphore;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>相应的，wait(S)和signal(S)操作可描述如下:</p><pre class="line-numbers language-none"><code class="language-none">wait(semaphore *S)&#123;    S-&gt;value--;    if(S-&gt;value&lt;0) block(S-&gt;list);&#125;signal(semaphore *S)&#123;    S-&gt;value++;    if(S-&gt;value&lt;&#x3D;0) wakeup(S-&gt;list);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>S-&gt;value的初值表示系统中某类资源的数目，对于每次wait操作意味着进程请求一个单位的该类资源，使系统中可供分配的该类资源减少一个，因此S-&gt;value–;当S-&gt;value&lt;0时说明该类资源已分配晚比。<br>因此进程应调用block原语进行自我阻塞，放弃处理机，并进入S-&gt;list中。<br>signal操作表示释放一个单位的资源，将S-&gt;value++，并waitup第一个list中阻塞的进程。</p><ol start="3"><li>AND型信号量<br>AND同步机制的基本思想是：将进程在整个运行过程中需要的所有资源，一次性全部地分配给进程，待进程使用完后再一起释放。</li></ol><blockquote><p>对若干个临界资源的分配采取原子操作方式：要么把它请求的资源全部分配到进程，要么一个也不分配。</p></blockquote><p>为此，在wait操作中增加一个“AND”条件，称为AND同步，或称为同时wait操作，S(Simultaneous wait)定义如下</p><pre class="line-numbers language-none"><code class="language-none">Swait(S1,S2,...,Sn)&#123;    while(TRUE)&#123;        if(Si&gt;&#x3D;1&amp;&amp;...&amp;&amp;Sn&gt;&#x3D;1)&#123;            for(i&#x3D;1;i&lt;&#x3D;n;i++) Si--;            break;        &#125;else&#123;            &#x2F;&#x2F; 进入等待队列        &#125;    &#125;&#125;Ssignal(S1,S2,...,Sn)&#123;    while(TRUE)&#123;        for(i&#x3D;1;i&lt;&#x3D;n;i++)&#123;            Si++;            &#x2F;&#x2F; 将所有在等待队列的Si的进程移除        &#125;    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li>信号量集</li></ol><p>对AND信号量机制的扩充，对进所申请的所有资源以及每类资源不同的资源需求量，再一次P、V原语操作中完成申请或释放。进程对信号量Si的测试值不再是1，而是该资源的分配下限指ti，即要求Si&gt;=ti，否则不予分配。进程对该资源的需求值为di，表示资源占用量，进行Si:=Si-di操作。由此形成一般化的“信号量集”机制，对应的Swait、Ssignal格式为：</p><blockquote><p>Si： 表示资源总量<br>ti： 分配资源下限值<br>di： 分配多少</p></blockquote><pre class="line-numbers language-none"><code class="language-none">Swait(S1,t1,d1,...,Sn,tn,dn);Ssignal(S1,t1,...,Sn,tn);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>一般“信号量集”还有下面几种特殊情况</p><ol><li>Swait(S,d,d)，此时在信号量集中只有一个信号量S，但允许它每次申请d个资源，当现有资源少于d时，不与分配</li><li>Swait(S,1,1)，此时信号量退化为一般信号量S(S&gt;1时)或互斥信号量S(S=1)</li><li>Swait(S,1,0)，当S&gt;=1时，允许多个进程进入某特定区，当S变为0后，将阻止任何进程进入特定区，相当于一个可控的开关</li></ol><h3 id="管程机制"><a href="#管程机制" class="headerlink" title="管程机制"></a>管程机制</h3><p><strong>定义</strong><br>代表共享资源的数据结构以及由对该共享数据结构实施操作的一组过程所组成的资源管理程序共同构成了一个操作系统的资源管理模块，称之为管程。<br>管程被请求和释放资源的进程所调用。<br>管程由四部分组成</p><ol><li>管程的名称</li><li>局部于管程的共享数据结构说明</li><li>对该数据结构进行操作的一组过程</li><li>对局部于管程的共享数据设置初始值的语句</li></ol><p>管程的语法描述：</p><pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; 管程名Monitor monitor_name &#123;    &#x2F;&#x2F; 共享变量说明    share variable declarations;    &#x2F;&#x2F; 条件变量说明    cond declarations;    &#x2F;&#x2F; 能被进程调用的过程    public:    &#x2F;&#x2F; 对数据结构操作的过程    void P1(...)&#123;...&#125;    void P2(...)&#123;...&#125;    &#x2F;&#x2F; ....    &#x2F;&#x2F; 管程主体    &#123;        &#x2F;&#x2F; 初始化代码        initialization code;    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>管程包含了面向对象的思想，将表征共享资源的数据结构及其对数据结构操作的一组过程，包括同步机制，都集中并封装在一个对象内部，隐藏了实现袭击。</p></blockquote><p>每次只能由一个进程请求管程的过程，从而实现了进程互斥。</p><p>应考虑的一种情况：当一个进程调用了管程，在管程中时被阻塞或挂起，直到阻塞或挂起的原因解除，而在此期间，如果该进程不释放管程，则其它进程无法进入管程，被迫长时间等待。</p><p>为此引入condition，管程中对每个条件变量都须予以说明，形式为: condition x,y；对条件变量的操作也仅为wait和signal，提供了两个操作,x.wait 和 x.signal</p><ul><li>x.wait：当正在调用管程的进程因x条件需要被阻塞或挂起，则调用x.wait将自己插入到x条件的等待队列上，并释放管程，直到x的条件变化。此时其它进程可以使用该管程</li><li>x.signal：正在调用管程的进程发现x条件发生了变化，则调用x.signal，重新启动一个因为x条件被挂起或阻塞的进程，如果有多个这样的进程则挑其中一个，如果没有则继续执行原进程。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;进程&quot;&gt;&lt;a href=&quot;#进程&quot; class=&quot;headerlink&quot; title=&quot;进程&quot;&gt;&lt;/a&gt;进程&lt;/h1&gt;&lt;p&gt;为了提高资源利用率和系统吞吐量，通常采用多道程序技术，将多个程序同时装进内存，并使之并发运行，此时作为资源分配和独立运行的基本单位都是进程。</summary>
      
    
    
    
    
    <category term="操作系统" scheme="http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="进程" scheme="http://example.com/tags/%E8%BF%9B%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>redis-事务</title>
    <link href="http://example.com/2019/10/07/redis-transaction/"/>
    <id>http://example.com/2019/10/07/redis-transaction/</id>
    <published>2019-10-07T09:12:34.000Z</published>
    <updated>2021-01-27T14:55:21.356Z</updated>
    
    <content type="html"><![CDATA[<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>redis通过<code>multi</code>,<code>exec</code>,<code>watch</code>等命令来实现事务功能。</p><p>例如</p><pre class="line-numbers language-none"><code class="language-none">127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; set &quot;name&quot; &quot;practical common lisp&quot;QUEUED127.0.0.1:6379&gt; get &quot;name&quot;QUEUED127.0.0.1:6379&gt; set &quot;author&quot; &quot;peter seibel&quot;QUEUED127.0.0.1:6379&gt; get &quot;author&quot;QUEUED127.0.0.1:6379&gt; exec1) OK2) &quot;practical common lisp&quot;3) OK4) &quot;peter seibel&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>像是sql里的，<code>start transaction</code>,<code>commit</code></p></blockquote><h2 id="事务的实现"><a href="#事务的实现" class="headerlink" title="事务的实现"></a>事务的实现</h2><p>一个事务从开始到结束通常会经历以下三个阶段</p><ol><li>事务开始</li><li>命令入队</li><li>事务执行</li></ol><p><code>multi</code>命令标志着事务的开始<br>如果客户端发送的命令为<code>exec</code>,<code>discard</code>,<code>watch</code>,<code>multi</code>命令其中一个，那么服务器立即执行这个命令，相反，发送的命令是上述4个以外的命令， 则不会立即执行这个命令，而会将这个命令放入一个事务队列里面，然后向客户端返回queue回复。</p><p><img src="https://user-images.githubusercontent.com/38010908/66283095-be119b80-e8f4-11e9-88fb-8101e7e5d34c.png" alt="image"></p><h2 id="WATCH命令的实现"><a href="#WATCH命令的实现" class="headerlink" title="WATCH命令的实现"></a>WATCH命令的实现</h2><p>watch命令是一个乐观锁，他可以在exec命令执行之前，监视任意数量的数据库键，并在exec命令执行时，检查被监视的键是否至少有一个被修改过了，如果是的话，服务器将拒绝执行事务，并向客户端返回代表事务执行失败的空回复</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;事务&quot;&gt;&lt;a href=&quot;#事务&quot; class=&quot;headerlink&quot; title=&quot;事务&quot;&gt;&lt;/a&gt;事务&lt;/h2&gt;&lt;p&gt;redis通过&lt;code&gt;multi&lt;/code&gt;,&lt;code&gt;exec&lt;/code&gt;,&lt;code&gt;watch&lt;/code&gt;等命令来实现事务</summary>
      
    
    
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis-集群</title>
    <link href="http://example.com/2019/10/07/redis-cluster/"/>
    <id>http://example.com/2019/10/07/redis-cluster/</id>
    <published>2019-10-07T09:12:25.000Z</published>
    <updated>2021-01-27T14:55:21.383Z</updated>
    
    <content type="html"><![CDATA[<h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><p>Redis集群是Redis提供的分布式数据库方案，集群通过分片(sharding)来进行数据共享，并提供复制和故障庄毅功能</p><h2 id="节点"><a href="#节点" class="headerlink" title="节点"></a>节点</h2><p>连接各个节点的工作可以使用<code>cluster meet</code>命令来完成</p><pre class="line-numbers language-none"><code class="language-none">cluster meet &lt;ip&gt; &lt;port&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>该命令可以让node节点与ip和port指定的节点进行握手，当握手成功时，node节点就会将ip和port所指定的节点添加到node节点当前所在的集群中</p><h3 id="启动节点"><a href="#启动节点" class="headerlink" title="启动节点"></a>启动节点</h3><p>一个节点就是一个运行在集群模式下的redis服务器，redis服务器在启动时会根据cluster-enabled配置选项是否为yes来决定是否开启服务器的集群模式</p><h3 id="集群数据结构"><a href="#集群数据结构" class="headerlink" title="集群数据结构"></a>集群数据结构</h3><p>clusterNode结构保存了一个节点的当前状态，比如节点的创建时间、节点的名字、节点当前的配置纪元、节点的ip地址和端口号等等</p><pre class="line-numbers language-c" data-language="c"><code class="language-c">struct clusterNode &#123;    &#x2F;&#x2F; 创建节点的时间    mstime_t ctime;    &#x2F;&#x2F; 节点的名字，由40个十六进制字符组成    char name[REDIS_CLUSTER_NAMELEN];    &#x2F;&#x2F; 节点标识    &#x2F;&#x2F; 使用各种不同的标识值记录节点的角色(比如主节点或者从节点)    &#x2F;&#x2F; 以及节点目前所处的状态    int flags;    &#x2F;&#x2F; 节点当前的纪元，用于实现故障转移    uint64_t configEpoch;    &#x2F;&#x2F; 节点的ip    char ip[REDIS_IP_STR_LEN];    &#x2F;&#x2F; 保存连接节点所需的有关信息    clusterLink *link;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>clusterLink保存了连接节点所需的有关信息，比如套接字描述符，输入缓冲区和输出缓冲区：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c">typedef struct clusterLink &#123;    &#x2F;&#x2F; 连接的创建时间    mstime_t ctime;    &#x2F;&#x2F; TCP套接字描述符    int fd;    &#x2F;&#x2F; 输出缓冲区，保存着等待发送其他节点的消息    sds sndbuf;    &#x2F;&#x2F; 输入缓冲区，保存着从其他节点接收到的消息    sds rcvbuf;    &#x2F;&#x2F; 与这个连接相关联的节点，如果没有的话就为null    struct clusterNode *node;&#125; clusterLink;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>每个节点都保存着一个clusterState结构，这个结构记录了在当前节点的视角下，集群目前所处的状态，例如集群是在线还是下线，集群包含多少个节点，集群当前的配置纪元，诸如此类：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c">typedef struct clusterState &#123;    &#x2F;&#x2F; 指向当前节点的指针    clusterNode *myself;    &#x2F;&#x2F; 集群当前的配置纪元，用户实现故障转移    uint64_t currentEpoch;    &#x2F;&#x2F; 集群当前的状态：是在线还是下线    int state;    &#x2F;&#x2F; 集群中至少处理着一个槽的节点的数量    int size;    &#x2F;&#x2F; 集群节点名单(包括myself节点)    &#x2F;&#x2F; 字典的键为节点的名字，字典的值为节点对应的clusterNode结构    dict *nodes;    &#x2F;&#x2F; ...&#125; clusterState;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://user-images.githubusercontent.com/38010908/66279710-b26aa880-e8e5-11e9-8823-b8108e95184b.png" alt="image"></p><h3 id="cluster-meet-命令实现"><a href="#cluster-meet-命令实现" class="headerlink" title="cluster meet 命令实现"></a>cluster meet 命令实现</h3><p><img src="https://user-images.githubusercontent.com/38010908/66279880-7552e600-e8e6-11e9-8b09-62dd7b99995a.png" alt="image"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;集群&quot;&gt;&lt;a href=&quot;#集群&quot; class=&quot;headerlink&quot; title=&quot;集群&quot;&gt;&lt;/a&gt;集群&lt;/h2&gt;&lt;p&gt;Redis集群是Redis提供的分布式数据库方案，集群通过分片(sharding)来进行数据共享，并提供复制和故障庄毅功能&lt;/p&gt;
&lt;h2 </summary>
      
    
    
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis-哨兵</title>
    <link href="http://example.com/2019/10/07/redis-sentinel/"/>
    <id>http://example.com/2019/10/07/redis-sentinel/</id>
    <published>2019-10-07T09:12:11.000Z</published>
    <updated>2021-01-27T14:55:21.379Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Sentinel哨兵"><a href="#Sentinel哨兵" class="headerlink" title="Sentinel哨兵"></a>Sentinel哨兵</h2><p>Sentinel哨兵是redis高可用的解决方案：由一个或多个sentinel实例组成的sentinel系统，可以监视任意多个主服务器，以及这些主服务器属下的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线主服务器属下的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求</p><h2 id="启动并初始化Sentinel"><a href="#启动并初始化Sentinel" class="headerlink" title="启动并初始化Sentinel"></a>启动并初始化Sentinel</h2><p>启动一个Sentinel可以使用命令</p><pre class="line-numbers language-none"><code class="language-none">$ redis-sentinel &#x2F;path&#x2F;to&#x2F;your&#x2F;sentinel.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>或者</p><pre class="line-numbers language-none"><code class="language-none">$ redis-server &#x2F;path&#x2F;to&#x2F;your&#x2F;sentinel.conf --sentinel<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>当一个sentinel启动时，它需要执行以下步骤：</p><ol><li>初始化服务器</li><li>将普通redis服务器使用的代码替换成sentinel专用代码</li><li>初始化sentinel状态</li><li>根据给定的配置文件，初始化sentinel的监视主服务器列表</li><li>创建连向主服务器的网络连接</li></ol><p>初始化服务器<br>sentinel本质上是一个运行在特殊模式下的redis服务器，所以启动sentinel的第一步就是初始化一个普通的redis服务器，不过sentinel不实用数据库，所以初始化不会载入rdb文件或者aof文件</p><h2 id="获取主服务器信息"><a href="#获取主服务器信息" class="headerlink" title="获取主服务器信息"></a>获取主服务器信息</h2><p>sentinel默认会每十秒一次的频率，通过命令连接向被监视的主服务器发送INFO命令，并通过分析INFO命令的回复来获取主服务器当前的信息</p><h3 id="获取从服务器信息"><a href="#获取从服务器信息" class="headerlink" title="获取从服务器信息"></a>获取从服务器信息</h3><p>当sentinel发现主服务器有新的从服务器出现时，sentinel除了会为这个新的从服务器创建相应的实例结构外，sentinel还会创建连接到从服务器的命令连接和订阅连接</p><h3 id="向主服务器和从服务器发送信息"><a href="#向主服务器和从服务器发送信息" class="headerlink" title="向主服务器和从服务器发送信息"></a>向主服务器和从服务器发送信息</h3><p>默认情况下，sentinel会以每两秒一次的频率，通过命令连接向所有被监视的主服务器和从服务器发送以下格式命令：</p><pre class="line-numbers language-none"><code class="language-none">PUBLISH __sentinel__:hello &quot;&lt;s_ip&gt;,&lt;s_port&gt;,&lt;s_runid&gt;,&lt;s_epoch&gt;,&lt;m_name&gt;,&lt;m_ip&gt;,&lt;m_port&gt;,&lt;m_epoch&gt;&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>命令向<code>__sentinel__:hello</code>频道发送了一条信息  </p><ul><li>其中s_开头的参数记录的是sentinel本身的信息</li><li>m_开头的记录的是主服务器的信息</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Sentinel哨兵&quot;&gt;&lt;a href=&quot;#Sentinel哨兵&quot; class=&quot;headerlink&quot; title=&quot;Sentinel哨兵&quot;&gt;&lt;/a&gt;Sentinel哨兵&lt;/h2&gt;&lt;p&gt;Sentinel哨兵是redis高可用的解决方案：由一个或多个sentine</summary>
      
    
    
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis-复制</title>
    <link href="http://example.com/2019/10/07/redis-replication/"/>
    <id>http://example.com/2019/10/07/redis-replication/</id>
    <published>2019-10-07T09:11:59.000Z</published>
    <updated>2021-01-27T14:55:21.382Z</updated>
    
    <content type="html"><![CDATA[<h2 id="复制功能的实现"><a href="#复制功能的实现" class="headerlink" title="复制功能的实现"></a>复制功能的实现</h2><p>为了解决旧版复制功能在处理断线重复制的低效问题，使用PSYNC命令代替SYNC命令来执行复制时的同步操作</p><p>PSYNC命令具有完整重同步(full resynchronization)和部分重同步(partial resynchronization)两种模式；</p><ul><li>其中完整重同步用于处理初次复制情况：完整重同步的执行步骤和SYNC命令的执行步骤基本一样，他们都是通过让主服务器创建并发送RDB文件，以及向从服务器发送保存在缓冲区里面的写命令来进行同步</li><li>而部分重同步则用于处理断线后重复制情况：当从服务器在断线后重新连接主服务器时，如果条件允许，主服务器可以将主从服务器连接断开期间的执行的写命令发送给从服务器，从服务器只要接受并执行这些写命令，就可以将数据库更新至主服务器当前所处的状态</li></ul><h3 id="部分重同步的实现"><a href="#部分重同步的实现" class="headerlink" title="部分重同步的实现"></a>部分重同步的实现</h3><p>部分重同步功能由以下三个部分构成：</p><ul><li>主服务器的复制偏移量(replication offset)和从服务器的复制偏移量</li><li>主服务器的复制和积压缓冲区(replication backlog)</li><li>服务器的允许ID(run ID)</li></ul><blockquote><p>复制积压缓冲区是由主服务器维护的一个固定长度(fixed-size)先进先出(FIFO)队列，默认大小为1MB。</p></blockquote><p>当主服务器进行命令传播时，它不仅会将写命令发送给所有从服务器，还会将写命令入对到复制积压缓冲区里面</p><p>当从服务器重新上线连上主服务器时，从服务器会通过PSYNC命令将自己的复制偏移量offset发送给主服务器，主服务器会根据这个复制偏移量来决定对从服务器执行何种同步操作</p><ul><li>如果offset偏移量之后的数据仍然存在于复制积压缓冲区里面，那么主服务器将对从服务器执行部分重同步操作</li><li>相反，如果offset偏移量之后的数据已经不存在于复制积压缓冲区，那么主服务器将对从服务器执行完整重同步操作</li></ul><blockquote><p>根据需要调整复制缓冲区的大小，为了安全起见，可以将复制积压缓冲区的大小设为 2 * second * write_size_per_second，这样可以保证绝大部分断线情况都能用部分重同步来处理</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;复制功能的实现&quot;&gt;&lt;a href=&quot;#复制功能的实现&quot; class=&quot;headerlink&quot; title=&quot;复制功能的实现&quot;&gt;&lt;/a&gt;复制功能的实现&lt;/h2&gt;&lt;p&gt;为了解决旧版复制功能在处理断线重复制的低效问题，使用PSYNC命令代替SYNC命令来执行复制时的同步</summary>
      
    
    
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis-数据库</title>
    <link href="http://example.com/2019/10/05/redis-databases/"/>
    <id>http://example.com/2019/10/05/redis-databases/</id>
    <published>2019-10-05T02:42:52.000Z</published>
    <updated>2021-01-27T14:55:21.372Z</updated>
    
    <content type="html"><![CDATA[<h2 id="过期键删除策略"><a href="#过期键删除策略" class="headerlink" title="过期键删除策略"></a>过期键删除策略</h2><p>redis过期删除策略由惰性删除跟定期删除配合组成</p><p>在规定时间内，分多次遍历服务器中的各个数据库，并从数据库的<code>expires</code>字典中随机检查一部分键的过期时间，并删除其中的键。</p><h2 id="AOF、RDB和复制功能对过期键的处理"><a href="#AOF、RDB和复制功能对过期键的处理" class="headerlink" title="AOF、RDB和复制功能对过期键的处理"></a>AOF、RDB和复制功能对过期键的处理</h2><h3 id="生成RDB文件"><a href="#生成RDB文件" class="headerlink" title="生成RDB文件"></a>生成RDB文件</h3><p>在执行<code>SAVE</code>或者<code>BGSAVE</code>命令创建一个新的RDB文件时，程序会对数据库中的键进行检查，已过期的键不会被保存到新创建的RDB文件中。</p><h3 id="载入RDB文件"><a href="#载入RDB文件" class="headerlink" title="载入RDB文件"></a>载入RDB文件</h3><p>这里会区分主从服务器的</p><ul><li>如果在主服务器模式下运行，载入RDB文件的时候，会对键进行检查，未过期的才会被载入到数据库中</li><li>如果在从服务器模式下运行，会全部载入数据库中。不过，因为主从服务器在进行数据同步的时候，从服务器的数据库会被清空，过期键对载入RDB文件的从服务器也不会造成影响</li></ul><h3 id="AOF文件写入"><a href="#AOF文件写入" class="headerlink" title="AOF文件写入"></a>AOF文件写入</h3><p>当服务器以AOF持久化模式运行时，如果数据库中某个键已经过期，但它还没被惰性删除或者定期删除，那么AOF文件不会因为这个过期键而产生任何影响<br>当过期键被惰性删除或者定期删除之后，程序会向AOF文件追加(append)一条DEL命令，来显式记录该键被删除</p><h3 id="AOF重写"><a href="#AOF重写" class="headerlink" title="AOF重写"></a>AOF重写</h3><p>在执行AOF重写过程中，会对键检查，已过期的键不会被保存到重写后的AOF文件中</p><h3 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h3><p>从服务器：  </p><ul><li>如果客户端请求从服务器，获取一个键，发现已过期，但是从服务器不会做任何处理，会把该键的值返回给客户端。</li><li>如果主服务器发来<code>DEL KEY</code>的命令，则会将对应的key删除</li></ul><p>主服务器：  </p><ul><li>如果客户端请求主服务器，获取一个键，发现已过期，主服务器会将该键删除，并返回空值，并会向从服务器发送<code>DEL KEY</code>的命令</li></ul><h2 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h2><p>RDB持久化既可以手动执行，也可以根据服务器配置选项定期执行，该功能可以将某个时间点上的数据库状态保存到一个RDB文件中。RDB所生成的RDB文件是一个经过压缩的二进制文件，通过该文件可以还原生成RDB文件时的数据库状态</p><blockquote><p>因为AOF文件的更新频率会比RDB文件更新频率更高，所以如果服务器开启了AOF持久化功能，那么服务器会优先使用AOF文件来还原数据库状态。只有AOF功能处于关闭状态时，服务器才会使用RDB文件来还原数据库状态。</p></blockquote><h2 id="AOF-Append-Only-File"><a href="#AOF-Append-Only-File" class="headerlink" title="AOF(Append Only File)"></a>AOF(Append Only File)</h2><p>与RDB持久化通过保存数据库中的键值对来记录数据库状态不同，AOF持久化时通过保存Redis服务器所执行的写命令来记录数据库状态的。</p><p>AOF持久化功能的实现可以分为命令追加(append)、文件写入、文件同步(sync)三个步骤</p><ol><li>命令追加： 服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区末尾</li><li>AOF文件的写入与同步</li></ol><h3 id="AOF文件的载入与数据还原"><a href="#AOF文件的载入与数据还原" class="headerlink" title="AOF文件的载入与数据还原"></a>AOF文件的载入与数据还原</h3><p><img src="https://user-images.githubusercontent.com/38010908/66124737-c7aab300-e617-11e9-97c2-6d7a72cff146.png" alt="image"></p><ol><li>创建一个不带网络连接的伪客户端</li><li>从AOF文件中分析并读取出一条写命令</li><li>使用伪客户端执行被读出一条写命令</li><li>一直重复步骤2和步骤3，直至AOF文件中的所有命令都被处理晚比为止</li></ol><h3 id="AOF重写-1"><a href="#AOF重写-1" class="headerlink" title="AOF重写"></a>AOF重写</h3><p>因为AOF持久化时通过保存被执行的写命令来记录数据库状态的，所以随着服务器运行时间的流逝，AOF文件中的内容会越来越多，体积越来越大，如果不加以控制的话，体积过大的AOF很可能对Redis服务器、甚至整个宿主机造成影响，并且AOF文件的题体积越来越大，使用AOF文件来进行数据还原所需的时间就越多。</p><p>为了解决AOF文件体积膨胀的问题，redis提供AOF文件重写(rewrite)功能。通过该功能redis服务器可以创建一个新的AOF文件来替代现有的AOF文件，新旧两个AOF文件所保存的数据库状态相同，但新AOF文件不会包含任何浪费空间的冗余命令，所以新的AOF通常比旧的AOF文件体积小的多</p><h3 id="AOF文件重写的实现"><a href="#AOF文件重写的实现" class="headerlink" title="AOF文件重写的实现"></a>AOF文件重写的实现</h3><p>AOF文件重写并不需要对现有的AOF文件进行任何读取、分析、写入操作，这个功能时通过读取数据库当前的数据库状态来实现的。</p><h3 id="AOF后台重写"><a href="#AOF后台重写" class="headerlink" title="AOF后台重写"></a>AOF后台重写</h3><p>在子进程工作的目的：</p><ul><li>子进程进行AOF重写期间，服务器进程(父进程)可以继续处理命令请求</li><li>子进程带有服务器进程的数据副本，使用子进程而不是线程，可以在避免使用锁的情况下保证数据的安全性</li></ul><p>为了避免在后台重写AOF的期间，有新的数据写入，则造成丢失</p><p>为了解决这种数据不一致问题，redis设置了一个AOF重写缓冲区，这个缓冲区在分局武器创建子进程之后开始使用，当redis服务器执行一个写命令之后，它会同时将这个写命令发送给AOF缓冲区和AOF重写缓冲区</p><h2 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h2><h3 id="文件事件"><a href="#文件事件" class="headerlink" title="文件事件"></a>文件事件</h3><p>redis基于reactor模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器(file event handler)：</p><ul><li>文件事件处理器使用I/O多路复用程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器</li><li>当被监听的套接字准备好进行连接应答、读取、写入、关闭等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件</li></ul><h3 id="文件事件处理器的构成"><a href="#文件事件处理器的构成" class="headerlink" title="文件事件处理器的构成"></a>文件事件处理器的构成</h3><p>I//O多路复用程序会将所有产生事件的套接字都放到一个队列里面，然后通过这个队列以有序、同步、每次一个套接字的方式向文件事件分派器传送套接字。</p><h2 id="时间事件"><a href="#时间事件" class="headerlink" title="时间事件"></a>时间事件</h2><p>redis的时间事件分为以下两类:</p><ul><li>定时事件：让一段程序在指定的事件之后执行一次</li><li>周期性事件：让一段程序每隔指定时间就执行一次</li></ul><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>服务器将所有时间事件都放在一个无序链表中，每当时间事件执行器运行时，它就遍历整个链表，查找所有已到达的时间事件，并调用相应的事件处理器</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;过期键删除策略&quot;&gt;&lt;a href=&quot;#过期键删除策略&quot; class=&quot;headerlink&quot; title=&quot;过期键删除策略&quot;&gt;&lt;/a&gt;过期键删除策略&lt;/h2&gt;&lt;p&gt;redis过期删除策略由惰性删除跟定期删除配合组成&lt;/p&gt;
&lt;p&gt;在规定时间内，分多次遍历服务器中的</summary>
      
    
    
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis-数据结构和对象</title>
    <link href="http://example.com/2019/10/05/redis-structure/"/>
    <id>http://example.com/2019/10/05/redis-structure/</id>
    <published>2019-10-05T02:42:43.000Z</published>
    <updated>2021-01-27T14:55:21.352Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简单动态字符串SDS"><a href="#简单动态字符串SDS" class="headerlink" title="简单动态字符串SDS"></a>简单动态字符串SDS</h2><p>Redis没有直接使用c语言传统的字符串表示，而是自己构建了一种名为简单动态字符串(simple dynamic string,SDS)的抽象类型，并将SDS用作Redis的默认字符串表示</p><blockquote><p>除了用来保存数据库中的字符串值之外，SDS还被用作缓冲区(buffer): AOF模块中的AOF缓冲区，以及客户端状态中的输入缓冲区，都是又SDS实现的。</p></blockquote><h3 id="SDS的定义"><a href="#SDS的定义" class="headerlink" title="SDS的定义"></a>SDS的定义</h3><pre class="line-numbers language-c" data-language="c"><code class="language-c">struct sdshdr &#123;    int len;    int free;    char buf[];&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="SDS与C字符串的区别"><a href="#SDS与C字符串的区别" class="headerlink" title="SDS与C字符串的区别"></a>SDS与C字符串的区别</h3><p>C字符串获取长度是需要逐个字符遍历的，时间复杂度为<code>O(n)</code>，而SDS的一个字段len用来记录长度，获取字符串长度时间复杂度为<code>O(1)</code></p><h3 id="杜绝缓冲区溢出"><a href="#杜绝缓冲区溢出" class="headerlink" title="杜绝缓冲区溢出"></a>杜绝缓冲区溢出</h3><h3 id="减少修改字符串带来的内存分配次数"><a href="#减少修改字符串带来的内存分配次数" class="headerlink" title="减少修改字符串带来的内存分配次数"></a>减少修改字符串带来的内存分配次数</h3><ul><li>空间预分配<br>如果对SDS修改后，SDS的长度小于1MB，那么程序会分配和len属性同样大小的未使用空间，这是len跟free的值相同。如果大于1MB，则程序会多分配1MB的未使用空间</li><li>惰性空间释放<br>惰性空间释放用于优化SDS字符串缩短操作。当SDS的api需要缩短sds保存的字符串时，程序并不立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性将这些字节数量记录起来，并等待使用。(其实就是单纯的不会去释放free的空间，留着说不定过年的时候加字符)</li></ul><h3 id="二进制安全"><a href="#二进制安全" class="headerlink" title="二进制安全"></a>二进制安全</h3><p>C字符串会根据空字符<code>\0</code>判断字符串是不是已经读完，可能导致某些特殊格式的二进制数据被错误的获取或写入。而sds是根据len这个属性判断的。</p><h2 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h2><pre class="line-numbers language-c" data-language="c"><code class="language-c">typedef struct listNode&#123;    struct listNode *prev;    struct listNode *next;    void *value;&#125;listNode;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>用过list来持有链表，主要为了方便操作</p><pre class="line-numbers language-c" data-language="c"><code class="language-c">typedef struct list &#123;    listNode *head;    listNode *tail;    unsigned long len;    &#x2F;&#x2F; 节点值复制函数    void *(*dup) (void *ptr);    &#x2F;&#x2F; 节点复制函数    void (*free) (void *ptr);    &#x2F;&#x2F; 节点值对比函数    int (*match)(void *ptr,void *key);&#125;list;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="字典-似乎也比较重要"><a href="#字典-似乎也比较重要" class="headerlink" title="字典(似乎也比较重要)"></a>字典(似乎也比较重要)</h2><p>Redis字典所用的哈希表又<code>dict.h/dictht</code>结构定义</p><pre class="line-numbers language-c" data-language="c"><code class="language-c">typedef struct dictht &#123;    &#x2F;&#x2F; 哈希表数组    dictEntry **table;    &#x2F;&#x2F; 哈希表大小    &#x2F;&#x2F; 记录的是哈希表的大小    unsigned long size;    &#x2F;&#x2F; 哈希表大小掩码，用于计算索引值    &#x2F;&#x2F; 该值总是等于size-1    &#x2F;&#x2F; 这个属性和哈希值一起决定一个键    &#x2F;&#x2F; 应该被放到table的哪个索引上    unsigned long sizemask;    &#x2F;&#x2F; 该哈希表已有的节点数量    &#x2F;&#x2F; 记录的是记录数，即键值对的数量    unsigned long used;&#125;dictht;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>哈希表节点</p><pre class="line-numbers language-c" data-language="c"><code class="language-c">typedef struct dictEntry &#123;    void *key;    union&#123;        void *val;        uint64_tu64;        int64_ts64;    &#125; v;    &#x2F;&#x2F; 指向下个哈希表节点，形成链表    struct dictEntry *next;&#125; dictEntry;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="rehash"><a href="#rehash" class="headerlink" title="rehash"></a>rehash</h3><p>扩展和收缩哈希表的工作可以通过rehash操作完成，redis对字典的哈希表执行rehash步骤：</p><ol><li>为字典ht[1]哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及ht[0]当前包含的键值对数量(也就是ht[0].used)</li></ol><ul><li>如果执行的是扩展操作，则ht[1]的大小为第一个大于等于ht[0].used*2的2的n次方</li><li>如果执行的是收缩操作，那么ht[1]的大小为第一个大于等他ht[0].used的2的n次方</li></ul><ol start="2"><li>将保存在ht[0]中的所有键值对rehash到ht[1]上，rehash指的是重新计算键的哈希值和索引值，然后将键值放到ht[1]的哈希表指定位置上</li><li>当ht[0]所有的键值都迁移到了ht[1]之后，释放ht[0]，将ht[1]设置为ht[0]，并在ht[1]新创建一个空白哈希表，为下一次rehash做准备</li></ol><h3 id="哈希表的扩展与收缩"><a href="#哈希表的扩展与收缩" class="headerlink" title="哈希表的扩展与收缩"></a>哈希表的扩展与收缩</h3><p>当以下条件中的任意一个被满足时，程序会自动开始对哈希表执行扩展操作：</p><ol><li>服务器目前没有在执行<code>BGSAVE</code>或者<code>BGREWRITEAOF</code>命令，并且哈希表的负载因子大于等于1</li><li>服务器目前正在执行<code>BGSAVE</code>或者<code>BGREWRITEAOF</code>命令，并且哈希表的负载因子大于等于5</li></ol><p>其中，哈希表的负载因子可以通过以下公式计算</p><pre class="line-numbers language-none"><code class="language-none">load_factor &#x3D; ht[0].used &#x2F; ht[0].size<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>当哈希表的负载因子小于0.1时，程序会自动对哈希表执行收缩操作</p><h2 id="渐进式rehash"><a href="#渐进式rehash" class="headerlink" title="渐进式rehash"></a>渐进式rehash</h2><p>渐进式rehash的详细步骤</p><ol><li>为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表</li><li>在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始</li><li>在rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性的值增一</li><li>随着字典操作的不断执行，最终在某个时间点上，ht[0]的所有键值对都会被rehash到ht[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成 </li></ol><blockquote><p>在渐进式rehash的过程中，字典会同时使用ht[0]和ht[1]两个哈希表，字典的delete,find,update操作会在两个哈希表上进行。例如要查找一个键的话，程序会现在ht[0]里面进行查找，没找到再去ht[1]里面找。另外，新添加的字典的键值对一律被保存到ht[1]里面，保证了ht[0]的键值对数量只减不增</p></blockquote><h2 id="跳跃表"><a href="#跳跃表" class="headerlink" title="*跳跃表"></a>*跳跃表</h2><blockquote><p>跳跃表(skiplist)是一种有序数据结构，通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的</p></blockquote><p>跳跃表支持平均O(logN)、最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点</p><p>Redis使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中的元素成员是比较长的字符串时，redis就会使用跳跃表作为有序集合键的底层实现</p><p><strong>去看看跳跃表</strong></p><h2 id="整数集合"><a href="#整数集合" class="headerlink" title="整数集合"></a>整数集合</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;简单动态字符串SDS&quot;&gt;&lt;a href=&quot;#简单动态字符串SDS&quot; class=&quot;headerlink&quot; title=&quot;简单动态字符串SDS&quot;&gt;&lt;/a&gt;简单动态字符串SDS&lt;/h2&gt;&lt;p&gt;Redis没有直接使用c语言传统的字符串表示，而是自己构建了一种名为简单动态</summary>
      
    
    
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>mysql-备份与恢复</title>
    <link href="http://example.com/2019/09/30/mysql-backup/"/>
    <id>http://example.com/2019/09/30/mysql-backup/</id>
    <published>2019-09-30T03:44:44.000Z</published>
    <updated>2021-01-27T14:55:21.385Z</updated>
    
    <content type="html"><![CDATA[<h2 id="备份与恢复概述"><a href="#备份与恢复概述" class="headerlink" title="备份与恢复概述"></a>备份与恢复概述</h2><p>根据备份方法的不同可以将备份分为：</p><ul><li>Hot Backup(热备)</li><li>Cold Backup(冷备)</li><li>Warm Backup(温备)</li></ul><p>按照备份后文件的内容，备份又可以分为</p><ul><li>逻辑备份</li><li>裸文件备份</li></ul><p>逻辑备份：<br>指备份出的文件内容是可读的，一般是文本文件。内容一般是一条条SQL语句。一般适用于数据库的升级、迁移等工作，缺点是恢复所需要的时间比较长</p><p>裸文件备份：<br>指数据库的物理文件，既可以是在数据库运行中复制，也可以是在数据库停止运行时直接的数据文件复制，这类备份的恢复时间往往较逻辑备份短很多</p><p>按照备份数据库的内容来分，备份又可以分为：</p><ul><li>完全备份</li><li>增量备份</li><li>日志备份</li></ul><blockquote><p>对于mysqldump备份工作来说，可以通过添加–single-transaction选项获得Innodb的一致性备份。此时的备份是在一个执行时间很长的事务中完成的。</p></blockquote><h2 id="冷备"><a href="#冷备" class="headerlink" title="冷备"></a>冷备</h2><p>只需要备份Mysql的frm文件，共享表空间文件，独立表空间文件(*.ibd)，重做日志文件。另外最好可以定期备份mysql的配置文件my.cnf</p><h2 id="逻辑备份"><a href="#逻辑备份" class="headerlink" title="逻辑备份"></a>逻辑备份</h2><p>mysqldump</p><h2 id="逻辑备份的恢复"><a href="#逻辑备份的恢复" class="headerlink" title="逻辑备份的恢复"></a>逻辑备份的恢复</h2><pre class="line-numbers language-none"><code class="language-none">mysql -uroot -p &lt;test_backup.sql<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>也可以</p><pre class="line-numbers language-none"><code class="language-none">source &#x2F;home&#x2F;mysql&#x2F;test_backup.sql<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="二进制日志备份与恢复"><a href="#二进制日志备份与恢复" class="headerlink" title="二进制日志备份与恢复"></a>二进制日志备份与恢复</h2><p>二进制日志非常关键，用户可以通过它完成point-in-time的恢复工作，mysql的replication同样需要二进制日志。在默认情况下并不启用二进制日志，要使用二进制日志首先必须启用它。在配置文件中进行设置<br>推荐的配置：</p><pre class="line-numbers language-ini" data-language="ini"><code class="language-ini">[mysqld]log-bin &#x3D; mysql-binsync_binlog &#x3D; 1innodb_support_xa &#x3D; 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="热备"><a href="#热备" class="headerlink" title="热备"></a>热备</h2><p>ibbackup是innodb官方提供的热备工具，是innodb备份的首选方式，不过是收费。但是！XtraBackup是免费了，实现了ibbackup所有的功能，并且扩展支持了真正的增量备份功能</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;备份与恢复概述&quot;&gt;&lt;a href=&quot;#备份与恢复概述&quot; class=&quot;headerlink&quot; title=&quot;备份与恢复概述&quot;&gt;&lt;/a&gt;备份与恢复概述&lt;/h2&gt;&lt;p&gt;根据备份方法的不同可以将备份分为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hot Backup(热备)&lt;/li&gt;</summary>
      
    
    
    
    
    <category term="mysql" scheme="http://example.com/tags/mysql/"/>
    
    <category term="innodb" scheme="http://example.com/tags/innodb/"/>
    
  </entry>
  
  <entry>
    <title>mysql-事务</title>
    <link href="http://example.com/2019/09/30/mysql-transaction/"/>
    <id>http://example.com/2019/09/30/mysql-transaction/</id>
    <published>2019-09-30T03:44:35.000Z</published>
    <updated>2021-01-27T14:55:21.371Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h2><p>innodb事务完全符合ACID特性</p><ul><li>原子性(atomicity)</li><li>一致性(consistency)</li><li>隔离性(isolation)</li><li>持久性(durability)</li></ul><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p>从事务的理论角度来说，可以把事务分为以下几种类型</p><ul><li>扁平事务(Flat Transactions)</li><li>带有保存点的扁平事务(Flat Transactions with Savepoints)</li><li>链事务(Chained Transactions)</li><li>嵌套事务(Nested Transactions)</li><li>分布式事务(Distributed Transactions)</li></ul><h2 id="事务的实现"><a href="#事务的实现" class="headerlink" title="事务的实现"></a>事务的实现</h2><p>原子性，一致性，持久性通过数据库的redo log和undo log来完成。redo log称为重做日志，用来保证事务的原子性和持久性。undo log用来保证事务的一致性。</p><h3 id="redo"><a href="#redo" class="headerlink" title="redo"></a>redo</h3><h2 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h2><ul><li>READ UNCOMMITTED</li><li>READ COMMITTED</li><li>REPEATABLE READ</li><li>SERIALIZABLE</li></ul><h2 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ACID&quot;&gt;&lt;a href=&quot;#ACID&quot; class=&quot;headerlink&quot; title=&quot;ACID&quot;&gt;&lt;/a&gt;ACID&lt;/h2&gt;&lt;p&gt;innodb事务完全符合ACID特性&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原子性(atomicity)&lt;/li&gt;
&lt;li&gt;一致性(co</summary>
      
    
    
    
    
    <category term="mysql" scheme="http://example.com/tags/mysql/"/>
    
    <category term="innodb" scheme="http://example.com/tags/innodb/"/>
    
  </entry>
  
  <entry>
    <title>mysql-锁</title>
    <link href="http://example.com/2019/09/30/mysql-lock/"/>
    <id>http://example.com/2019/09/30/mysql-lock/</id>
    <published>2019-09-30T03:43:36.000Z</published>
    <updated>2021-01-27T14:55:21.372Z</updated>
    
    <content type="html"><![CDATA[<h2 id="InnoDB存储引擎中的锁"><a href="#InnoDB存储引擎中的锁" class="headerlink" title="InnoDB存储引擎中的锁"></a>InnoDB存储引擎中的锁</h2><p>锁的类型，InnoDB存储引擎实现了如下两种标准的行级锁：</p><ul><li>共享锁(S Lock)，允许事务读一行数据</li><li>排它锁(X Lock)，允许事务删除或更新一行数据</li></ul><blockquote><p>如果一个事务T1已经获得了行r的共享锁，那么另外的事务T2可以立即获得行r的共享锁，因为读取并没还有改变行r的数据，称这种情况为锁兼容(Lock Compatible)，若有其他的事务T3想获得行r的排他锁，则其必须等待事务T1、T2释放行r上的共享锁——这种情况称为锁不兼容。</p></blockquote><table><thead><tr><th>-</th><th>X</th><th>s</th></tr></thead><tbody><tr><td>X</td><td>不兼容</td><td>不兼容</td></tr><tr><td>S</td><td>不兼容</td><td>兼容</td></tr></tbody></table><blockquote><p>需要注意的是，S和X锁都是行锁，兼容是指同一记录(row)锁的兼容性情况</p></blockquote><h3 id="意向锁-Intention-Lock-IX"><a href="#意向锁-Intention-Lock-IX" class="headerlink" title="意向锁(Intention Lock) IX"></a>意向锁(Intention Lock) IX</h3><p>意向锁是将锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度(fine granularity)上进行加锁。 如下图所示</p><p><img src="https://user-images.githubusercontent.com/38010908/65810810-fb35a980-e1e1-11e9-9896-f910d181bf44.png" alt="image"></p><p>总结来说的话，就是对最细粒度的对象进行上锁的话，需要对粗粒度的对象上IX锁，也就是意向锁，但是会存在兼容性的问题</p><p>InnoDB在支持意向锁设计比较简练，其意向锁即为表级别的锁。设计目的主要是为了在一个事务中揭示下一行将被请求的锁类型。其支持两种意向锁</p><ul><li>意向共享锁(IS Lock)，事务想要获得一张表中某几行的共享锁</li><li>意向排它锁(IX Lock)，事务想要获得一张表中某几行的排它锁</li></ul><p>由于InnoDB支持的是行级别的锁，因此意向锁其实不会阻塞全表扫以外的任何请求。故表级意向锁与行级锁的兼容性如下</p><blockquote><p>我理解的应该这么说 (列)想要获得表(行)上的一个(列)锁，e.g. IS想要获得表的IS锁，所以是兼容的</p></blockquote><table><thead><tr><th>-</th><th>IS</th><th>IX</th><th>S</th><th>X</th></tr></thead><tbody><tr><td>IS</td><td>兼容</td><td>兼容</td><td>兼容</td><td>不兼容</td></tr><tr><td>IX</td><td>兼容</td><td>兼容</td><td>不兼容</td><td>不兼容</td></tr><tr><td>S</td><td>兼容</td><td>不兼容</td><td>兼容</td><td>不兼容</td></tr><tr><td>X</td><td>不兼容</td><td>不兼容</td><td>不兼容</td><td>不兼容</td></tr></tbody></table><h3 id="一致性非锁定读"><a href="#一致性非锁定读" class="headerlink" title="一致性非锁定读"></a>一致性非锁定读</h3><p>一致性非锁定读是指InnoBD存储引擎通过行多版本控制的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行DELETE或UPDATE操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB会去读取行地一个快照数据。</p><p><img src="https://user-images.githubusercontent.com/38010908/65813202-76a85280-e204-11e9-9f31-2c0b80c7d440.png" alt="image"></p><blockquote><p>快照数据时指该行地之前版本地数据，该实现是通过undo段来完成地。而undo用来在事务中回滚数据，因此此快照数据本身是没有额外地开销。此外，读取快照数据是不需要上锁地，因为没有事务需要对历史地数据进行修改操作。在默认设置下，这是默认的读取方式，但在不同事务隔离级别下，读取的方式不同，并不是在每个事务隔离级别下都是采用非锁定的一致性读。此外，即使都是使用非锁定的一致性读，但是对于快照数据的定义也各不相同。</p></blockquote><p><strong>多版本并发控制</strong><br>一个行记录可能有不止一个快照数据，一般称这种技术为行多版本技术，由此带来的并发控制，称之为多版本并发控制。</p><p>下面有个例子，用于说明在READ COMMITED 与 READ REPEATABLE不同的事务隔离级别下，读取的方式区别</p><p>如下图，COMMITED READ级别下，总是读取最新的版本，即会话A最开始读取到id为1，在会话B更新了id为3，然后commit后，A仍然会读取最新的版本，所以select id为1就不存在了，因为最新的版本id是3。<br>而在READ REPEATABLE下，始终会读取最初始的版本，所以读取到的id仍然为1</p><p><img src="https://user-images.githubusercontent.com/38010908/65813440-d5230000-e207-11e9-8282-c52c03d82786.png" alt="image"></p><blockquote><p>需要特别注意的是，对于READ COMMITED 的事务隔离级别而言，从数据库理论的角度看，其违反了事务ACID中的I的特性，即隔离性。</p></blockquote><h3 id="一致性锁定读"><a href="#一致性锁定读" class="headerlink" title="一致性锁定读"></a>一致性锁定读</h3><p>在默认配置下，READ COMMITED 跟 REPEATABLE READ这两种事务隔离级别下都是采用非锁定读的。但在某些情况下，用户需要显式地对数据库读取操作进行加锁保证数据逻辑地一致性。</p><p>InnoDB对于select语句支持两种一致性锁定读(locking read)操作</p><ul><li><code>SELECT ... FOR UPDATE</code> 对读取地行记录加一个X锁，其他事务不能对已锁定地行加上任何锁</li><li><code>SELECT ... LOCK IN SHARE MODE</code> 对读取地行记录加一个S锁，其他事务可以向被锁定地行加S锁，但是如果加X锁，则会被阻塞</li></ul><blockquote><p>对于上述连个SELECT锁定语句时，务必加上BEGIN，START TRANSACTION或者SET AUTOCOMMIT=0</p></blockquote><h3 id="自增长与锁"><a href="#自增长与锁" class="headerlink" title="自增长与锁"></a>自增长与锁</h3><p><code>innodb_autoinc_lock_mode</code>，总共有3个有效值可供设定，0、1、2</p><p><img src="https://user-images.githubusercontent.com/38010908/65813794-42389480-e20c-11e9-81a1-4eabdc119daf.png" alt="image"></p><h3 id="外键和锁"><a href="#外键和锁" class="headerlink" title="外键和锁"></a>外键和锁</h3><p>对于一个外键列，如果没有显示地对这个列加索引，InnoDB会自定对其加一个索引，因为这样可以避免表锁。(我：可能因为全表扫描不会采用一致性非锁定读？而会采用表锁？只在读的情况下？)</p><p>对于外键值的插入或更新，首先需要查询父表中的记录，即SELECT父表。但是对于父表的SELECT操作，不是使用一致性非锁定读的方式，因为这样会发生数据不一致的问题，因此这是使用的时<code>SELECT ... LOCK IN SHARE MODE</code>方式，即主动对父表加一个S锁。如果这时父表上已经这样加了X锁，子表上的操作会被阻塞。</p><p><img src="https://user-images.githubusercontent.com/38010908/65813876-60eb5b00-e20d-11e9-8145-c706acc8a439.png" alt="image"></p><p>两个会话都没有进行COMMIT或ROLLBACK操作，而会话B被阻塞的原因是：<br>id为3的父表在A中已经加了一个X锁(因为是DELETE操作？)，然和人B中又需要对id为3的行获取一个S锁，此时INSERT操作会被阻塞。</p><p>如果此时采用的是一致性非锁定读，这是Session B就会读到父表有id为3的记录，可以插入数据库。但是如果会话A对事务提交了，父表中就不存在id为3的记录。数据在父、子表就会存在不一致的情况。</p><h2 id="锁的算法"><a href="#锁的算法" class="headerlink" title="锁的算法"></a>锁的算法</h2><h3 id="行锁的3种算法"><a href="#行锁的3种算法" class="headerlink" title="行锁的3种算法"></a>行锁的3种算法</h3><ul><li>Record Lock: 单个行记录上的锁</li><li>Gap Lock：间隙锁，锁定一个范围，但不包含记录本身</li><li>Next-Key Lock： Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身</li></ul><p><strong>Next-Key Lock</strong> </p><p>如果一个索引有10，11，13，20四个值，那么该索引可能被next-key locking的区间为：</p><ul><li>(-∞,10]</li><li>(10,11]</li><li>(11,13]</li><li>(13,20]</li><li>(20,+∞]</li></ul><p>采用Next-Key lock的锁定技术称为 Next-Key Locking。其设计的目的是为了解决幻读(Phantom Problem)，利用这种锁定技术，锁定的不是单个值，而是一个方位，是谓词锁(predict lock)的一种改进。</p><p>若事务T1已经通过next-key lock锁定了如下范围<br><code>(10,11]、(11,13]</code><br>当插入新的记录12时，则锁定的范围会变成:<br><code>(10,11]、(11,12]、(12,13]</code>  </p><blockquote><p>然后当查询的索引含有唯一属性时，innodb会对next-key lock进行优化，将其降级为Record lock，即仅锁住索引本身，而不是范围。</p></blockquote><p>举个栗子，创建了如下表(z)</p><table><thead><tr><th>a(主键)</th><th>b(辅助索引)</th></tr></thead><tbody><tr><td>1</td><td>1</td></tr><tr><td>3</td><td>1</td></tr><tr><td>5</td><td>3</td></tr><tr><td>7</td><td>6</td></tr><tr><td>10</td><td>8</td></tr></tbody></table><p>当在会话A执行下面的SQL语句：</p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">SELECT * FROM z WHERE b &#x3D; 3 FOR UPDATE<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>此时sql通过索引b进行查询，因为时非唯一的辅助索引，所以采用了传统的next-key locking技术，并且由于有两个索引，其需要分别进行锁定。对于聚集索引来说，其仅对列a等于5的索引加上record lock。所以对于辅助索引，其加上了Next-Key Lock，锁定的范围是(1,3)。 <strong>需要特别注意的是，InnoDB还会对辅助索引的下一个键值加上gap lock,即还有一个辅助索引范围为(3,6)的锁</strong> 因此，若在新会话B中允许下面的SQL语句，都会被阻塞</p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">SELECT * FROM z WHERE a &#x3D; 5 LOCK IN SHARE MODE;INSERT INTO z SELECT 4,2INSERT INTO z SELECT 6,5<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>分析：<br>第一个sql语句不能执行，因为A中的sql已经对聚集索引列中a=5的值加上了X锁，因此会被阻塞。<br>第二句sql语句，主键插入4没有问题，但是插入的辅助索引值为2在锁定范围(1,3)之间，因此会被阻塞<br>第三个sql语句，主键插入6没有问题，没有被锁定，索引5插入不在(1,3)中，但是在(3,6)中，所以依然会被锁定。</p><p>但是如果执行以下sql，是不会被阻塞的  </p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">INSERT INTO z SELECT 8,6INSERT INTO z SELECT 2,0INSERT INTO z SELECT 6,7<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>从上面例子可以看到，Gap Lock为了阻止多个事务将记录插入到同一范围内，而这回导致幻读的产生。<br>例如上面的例子中，会话A中已经锁定b=3的记录。若此时没有gap lock锁定(3,6)，那么用户可以插入索引b列为3的记录，这会导致会话A中的用户再次执行同样查询时会返回不同的记录，即幻读(Phantom Problem)。</p><p>在innodb存储引擎中，对于insert操作，会检查插入记录的下一条记录是否被锁定，若已经被锁定，则不允许查询。</p><blockquote><p>对于唯一键值的锁定，Next-Key Lock降级为Record Lock仅存在于查询所有的唯一索引列。若唯一索引由多个列组成，而查询仅是查找多个唯一索引列中的其中一个，那么查询其实是range类型查询，而不是point类型查询，故innodb依然使用next-key lock进行锁定</p></blockquote><h3 id="解决-Phantom-Problem-幻读"><a href="#解决-Phantom-Problem-幻读" class="headerlink" title="解决(Phantom Problem)幻读"></a>解决(Phantom Problem)幻读</h3><p>在默认的事务隔离级别下，即REPEATABLE READ下，innodb采用next-key locking机制来避免幻读问题。</p><blockquote><p><strong>Phantom Problem是指同一事务下，连续执行2次同样的SQL语句可能导致不同的结果，第二次的SQL语句可能返回之前不存在的行</strong></p></blockquote><p>举个栗子，创建一个表t,<code>CREATE TABLE t (a INT PRIMARY KEY);</code></p><table><thead><tr><th>a</th></tr></thead><tbody><tr><td>1</td></tr><tr><td>2</td></tr><tr><td>5</td></tr></tbody></table><p>若此时事务T1执行如下语句<br><code>SELECT * FROM t WHERE a&gt;2 FOR UPDATE;</code><br>注意，此时事务T1并没有进行提交操作，上述应该返回5这个结果。若此时另一个事务T2插入了4这个值(假设数据库允许这个操作)那么事务T1再次执行上述SQL，会得出结果4、5，这与第一次得到的结果不同，违反了事务的隔离性。</p><p>InnoDB采用了Next-Key Locking的算法避免了幻读。对于上述sql语句，其锁住的不是5这单个值，而是对(2,+∞)这个范围加了X锁，因此对于这个范围的插入操作时不被允许的，从而避免幻读。</p><h3 id="唯一性检查"><a href="#唯一性检查" class="headerlink" title="唯一性检查"></a>唯一性检查</h3><p>背景介绍：</p><blockquote><p>在开发过程中，很多时候，我们有很多的需求都需要“若不存在则插入”的需求。</p></blockquote><p>然后目前做法是如下面的代码，但是这里会有个并发问题，因为这不是一个原子操作，在并发情况下可能会出现多个name相同的问题，当然这个可以在数据库里面做限制，name设置称unique</p><pre class="line-numbers language-golang" data-language="golang"><code class="language-golang">user :&#x3D; dao.getUserByName(name)if user !&#x3D; nil &#123;    return &quot;该用户名已存在&quot;&#125;dao.insertUser(&amp;User&#123;Name:name&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>所以不设置unique的时候在想，有没有这样一种方法，但是并没有</p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">insert into user(name) values(name) where name !&#x3D; &#39;name&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后现在知道了多一个用法，当然，需要开启一个事务</p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">select * from user where name &#x3D; &#39;name&#39; lock in share mode;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>用法与上面第一种一致，但是在执行的时候，只有一个事务会成功，别的都会抛出死锁的错误</p><pre class="line-numbers language-golang" data-language="golang"><code class="language-golang">dao.insertUser(&amp;User&#123;Name:name&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="锁问题"><a href="#锁问题" class="headerlink" title="锁问题"></a>锁问题</h2><blockquote><p>通过锁定机制可以实现事务的隔离性要求，使得事务可以并发地工作。锁提高了并发，却会带来潜在地问题。不过因为事务隔离性地要求，锁只会带来三种问题，防止这三种情况地发生，那将不会产生异常。</p></blockquote><h3 id="脏读"><a href="#脏读" class="headerlink" title="脏读"></a>脏读</h3><p>脏数据是指未提交地数据，如果读到脏数据，即一个事务可以读到另外一个事务中为提交地数据，显然违反了数据库地隔离性。</p><p>READ UNCOMMITTED(未提交读)</p><blockquote><p>脏读隔离看似毫无用处，但在一些比较特殊地情况下还是可以将事务地隔离级别设置为READ UNCOMMITTED。例如replication环境中地slave节点，并且该slave上的查询并不需要特别精确的返回值</p></blockquote><h3 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h3><p>READ COMMITTED(提交读)</p><p>同一个事务内两次读取数据不一样的情况。一般来说，不可重复读的问题可以接受，因为其读到的是已经提交的数据，本身不会带来很大的问题。</p><blockquote><p>在innodb中，通过使用Next-Key Lock算法来避免不可重复读。在MySQL文档中，将不可重复的也定义成幻读。在Next-Key Lock算法下，对于索引的扫描，不仅锁住扫描到的索引，而且还锁住这些索引覆盖到的范围(gap)。因此这个范围内的插入都是不允许的，这样就避免了另外的事务在这个范围内插入数据导致的不可重复度的问题。</p></blockquote><h3 id="丢失更新"><a href="#丢失更新" class="headerlink" title="丢失更新"></a>丢失更新</h3><p>丢失更新是另一个锁导致的问题，就是一个事务的更新操作被另一个事务的更新操作覆盖了，从而导致数据的不一致。</p><p>避免更新丢失的做法就是将操作并行化，也就是获取一个排它锁，所以在一个事务中可以这么使用</p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">SELECT * FROM XX WHERE id&#x3D;? FOR UPDATE<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="阻塞"><a href="#阻塞" class="headerlink" title="阻塞"></a>阻塞</h2><p>在innodb中，参数<code>innodb_lock_wait_timeout</code>用来控制等待时间(默认是50秒),<code>innodb_rollback_on_timeout</code>(静态的，不可在启动时进行修改)来设定是否在等待超时时间对进行中的事务进行回滚(默认是OFF，代表不回滚)，<code>innodb_lock_wait_timeout</code>是动态的，可以在MySQL数据库运行时进行调整</p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">SET @@innodb_lock_wait_timeout&#x3D;60;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><blockquote><p>死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象</p></blockquote><p>除了<del>超时机制</del> 当前数据库普遍采用wait-for graph(等待图)的方式来进行死锁检测。较之超时的解决方案，这是一种更为主动的死锁检测机制。innodb也采用这种方式。wait-for graph要求数据库保存以下两种信息：</p><ul><li>锁的信息链表</li><li>事务等待链表</li></ul><p>通过上述链表可以构造出一张图，而在这个图中若存在回路，则代表存在死锁，因此资源间相互发生等待。在wait-for graph中，事务为图中的节点，而在图中，事务T1指向T2边的定义为：</p><ul><li>事务T1等待事务T2所占用的资源</li><li>事务T1最终等待T2所占用的资源，也就是事务之间在等待相同的资源，而事务T1发生在事务T2的后面</li></ul><p>看下面一个例子</p><p><img src="https://user-images.githubusercontent.com/38010908/65825941-9cd6fc80-e2af-11e9-9ec7-b3f1fee6b16c.png" alt="image"></p><p>看到Transaction Wait Lists中共有4个事务，故在wait-for graph中应有4个节点</p><p><img src="https://user-images.githubusercontent.com/38010908/65825971-f2aba480-e2af-11e9-93fa-1146a2b7d69f.png" alt="image"></p><p>因为t2对row1占用了x锁，t1对row2占用了s锁，t1需要等待t2中row1的资源，因此在wait-for graph中有条边从节点t1指向了t2.<br>而又因为t2需要等待t1、t4所占用了row2资源，所以存在t2到t1、t4的边。<br>同样，t3需要等待t1,t4,t2所占用的tow2资源，所以有一条t3到t1,t4,t2的边。<br>因此最终的wait-for graph如下图所示</p><p><img src="https://user-images.githubusercontent.com/38010908/65826006-89786100-e2b0-11e9-9a11-2c7e09565bf4.png" alt="image"></p><p>通过上述例子，可以发现wait-for graph是一种较为主动的死锁检测机制，在每个事务请求锁并发生等待时都会判断是否存在回路，若存在则有死锁，通常来说innodb选择回滚undo量最小的事务</p><blockquote><p>wait-for graph的死锁检测通常采用深度优先算法实现</p></blockquote><h3 id="锁升级"><a href="#锁升级" class="headerlink" title="锁升级"></a>锁升级</h3><p>锁升级是指锁的粒度降低，e.g 行锁升级成页锁，页锁升级成表锁</p><blockquote><p>innodb根据页进行加锁，并采用位图的方式。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;InnoDB存储引擎中的锁&quot;&gt;&lt;a href=&quot;#InnoDB存储引擎中的锁&quot; class=&quot;headerlink&quot; title=&quot;InnoDB存储引擎中的锁&quot;&gt;&lt;/a&gt;InnoDB存储引擎中的锁&lt;/h2&gt;&lt;p&gt;锁的类型，InnoDB存储引擎实现了如下两种标准的行</summary>
      
    
    
    
    
    <category term="mysql" scheme="http://example.com/tags/mysql/"/>
    
    <category term="innodb" scheme="http://example.com/tags/innodb/"/>
    
  </entry>
  
  <entry>
    <title>mysql-索引与外键</title>
    <link href="http://example.com/2019/09/30/mysql-index-and-foreign-key/"/>
    <id>http://example.com/2019/09/30/mysql-index-and-foreign-key/</id>
    <published>2019-09-30T03:42:18.000Z</published>
    <updated>2021-01-27T14:55:21.366Z</updated>
    
    <content type="html"><![CDATA[<h2 id="innodb存储引擎索引概述"><a href="#innodb存储引擎索引概述" class="headerlink" title="innodb存储引擎索引概述"></a>innodb存储引擎索引概述</h2><p>innodb常见的索引</p><ul><li>B+树索引</li><li>全文索引</li><li>哈希索引</li></ul><blockquote><p>B+树索引并不能找到一个给定键值的具体行。B+树索引能找到的只是被查找数据行所在的页。然后数据库通过页读入到内存，再在内存中进行查找，最后得到要查找的数据。</p></blockquote><h2 id="数据结构和算法"><a href="#数据结构和算法" class="headerlink" title="数据结构和算法"></a>数据结构和算法</h2><blockquote><p>晚点去学习下B+树</p></blockquote><h2 id="B-树索引"><a href="#B-树索引" class="headerlink" title="B+树索引"></a>B+树索引</h2><blockquote><p>B+索引在数据库中又一个特点是高扇出性，因此在数据库中，B+树的高度一般在2～4层。</p></blockquote><blockquote><p>数据库中B+树索引可以分为聚集索引和辅助索引，但其内部都是B+树，即高度平衡的，叶子节点存放着所有的数据。聚集索引与辅助索引不同的是，叶子节点存放的是否是一整行的信息</p></blockquote><h2 id="聚集索引"><a href="#聚集索引" class="headerlink" title="聚集索引"></a>聚集索引</h2><blockquote><p>innodb存储引擎表是索引组织表，即表中数据按主键顺序存放。而聚集索引(clustered index)就是按照每张表的主键构造一棵B+树，同时<strong>叶子节点中存放的即为整张表的行记录数据</strong>，也将聚集索引的叶子节点成为数据页。聚集索引的这个特性决定了索引组织表中数据也是索引的一部分。同B+树数据结构一样，每个数据页都通过一个双向链表来进行链接</p></blockquote><h2 id="辅助索引-Secondary-Index-也称非聚集索引"><a href="#辅助索引-Secondary-Index-也称非聚集索引" class="headerlink" title="辅助索引(Secondary Index,也称非聚集索引)"></a>辅助索引(Secondary Index,也称非聚集索引)</h2><blockquote><p>叶子节点并不包含行记录的全部数据。叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含了一个书签(bookmark)</p></blockquote><p>书签  </p><blockquote><p>该书签用来告诉InnoDB存储引擎哪里可以找到与索引相对应的行数据。由于InnoDB是索引组织表，因此InnoDB的辅助索引的书签就是相应行数据的聚集索引键。</p></blockquote><h2 id="B-树索引的分裂"><a href="#B-树索引的分裂" class="headerlink" title="B+树索引的分裂"></a>B+树索引的分裂</h2><p>没看懂</p><h2 id="Cardinality"><a href="#Cardinality" class="headerlink" title="Cardinality"></a>Cardinality</h2><p>如何查看索引是否是高选择性？</p><p>可以通过<code>show index</code>结果中的列<code>Cardinality</code>来观察。Cardinality值非常关键，表示索引中不重复记录的预估值。值得注意的是该值是一个预估值并不是准确的值。实际应用中<code>Cardinality/n_rows_in_table</code>应尽可能地接近1.</p><h2 id="Multi-Range-Read优化"><a href="#Multi-Range-Read优化" class="headerlink" title="Multi-Range Read优化"></a>Multi-Range Read优化</h2><p>MySQL5.6开始支持Multi-Range Read(MRR)优化，MRR优化的目的为了减少磁盘的随机访问，并将随机访问转化为较为顺序的数据访问，这对IO-bound类型的SQL查询语句可带来性能极大的提升。MRR优化可适用于range，ref，eq_ref类型的查询。</p><p>MRR优化有以下几个好处</p><ul><li>MRR使数据访问变得较为顺序。在查询辅助索引时，首先根据得到的查询结果按照主键进行排序，并且按照主键排序的顺序进行书签查找</li><li>减少缓冲池中页被替换的次数</li><li>批量处理对键值的查询操作</li></ul><p>对于InnoDB和MyISAM的范围查询和JOIN查询操作，MRR工作方式如下：</p><ul><li>将查询得到的辅助索引键值存放于一个缓存中，这时缓存中的数据是根据辅助索引键值排序的</li><li>将缓存中的键值根据RowID进行排序</li><li>根据RowID的排序顺序来访问实际的数据文件</li></ul><blockquote><p>此外，若InnoDB或MyISAM缓冲池不是足够大，不能放下一张表中的所有数据，此时频繁的离散读操作还会导致缓存中的页被替换出缓冲池，然后又不断地读入缓冲池。若是按照主键顺序进行访问，则可以将此重复行为降为最低</p></blockquote><h2 id="Index-Condition-Pushdown-ICP-优化"><a href="#Index-Condition-Pushdown-ICP-优化" class="headerlink" title="Index Condition Pushdown (ICP) 优化"></a>Index Condition Pushdown (ICP) 优化</h2><p>ICP同样是MySQL5.6开始支持的一种根据索引进行查询的优化方式。</p><p>之前的MySQL版本不支持ICP的话，当进行索引查询时，首先根据索引来查找记录，然后再根据<code>WHERE</code>条件来过滤记录。</p><p>在支持ICP之后，<code>WHERE</code>操作放在了存储引擎层，在取出索引的同时根据<code>WHERE</code>条件过滤。在某些查询下，可以大大减少上层SQL层对记录的索取，从而提高数据库的整体性能。</p><h2 id="哈希算法"><a href="#哈希算法" class="headerlink" title="哈希算法"></a>哈希算法</h2><h3 id="InnoDB中的哈希算法"><a href="#InnoDB中的哈希算法" class="headerlink" title="InnoDB中的哈希算法"></a>InnoDB中的哈希算法</h3><p>对于缓冲池的哈希表来说，在缓冲池中的Page都有一个<code>chain</code>指针，他指向相同哈希函数值的页。</p><blockquote><p>对于除法散列，m的取值为略大于2倍的缓冲池页的质数。例如：当前参数<code>innodb_buffer_pool_size</code>的大小为10M，则公有640个16kb的页。对于缓冲池内存的哈希表来说，需要分配640*2=1280个槽，但是由于128不是质数，需要取比1280略大的质数，应该是1399，所以启动时会分配1399个槽的哈希表。</p></blockquote><p>那么innodb的缓冲池对于其中的页是怎么进行查找的？</p><p>innodb的表空间都有一个space<code>_id</code>，用户要查找的应该是某个表空间的某个连续16kb的页，即偏移量offset。innodb将<code>space_id</code>左移20位，然后加上这个<code>space_id</code>和offset，即关键字<code>K=space_id&lt;&lt;20 + space_id + offset</code>，然后通过除法散列到各个槽中去。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;innodb存储引擎索引概述&quot;&gt;&lt;a href=&quot;#innodb存储引擎索引概述&quot; class=&quot;headerlink&quot; title=&quot;innodb存储引擎索引概述&quot;&gt;&lt;/a&gt;innodb存储引擎索引概述&lt;/h2&gt;&lt;p&gt;innodb常见的索引&lt;/p&gt;
&lt;ul&gt;
&lt;</summary>
      
    
    
    
    
    <category term="mysql" scheme="http://example.com/tags/mysql/"/>
    
    <category term="innodb" scheme="http://example.com/tags/innodb/"/>
    
  </entry>
  
</feed>
